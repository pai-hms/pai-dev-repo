import streamlit as st
import os
import time
import asyncio
import uuid
import json
import csv
import io
import pandas as pd
from typing import Dict, Any, List, Generator
from agent import create_agent, SupervisedAgent
from tools import create_tavily_tool

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="PAI Web Agent",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ê³ ê¸‰ CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        margin-bottom: 2rem;
        background: linear-gradient(90deg, #1f77b4, #ff7f0e);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    .chat-container {
        max-height: 600px;
        overflow-y: auto;
        padding: 1rem;
        border: 1px solid #e0e0e0;
        border-radius: 0.5rem;
        background-color: #fafafa;
    }
    .streaming-message {
        background-color: #fff3e0;
        border-left: 4px solid #ff9800;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
        animation: pulse 1.5s infinite;
    }
    @keyframes pulse {
        0% { opacity: 1; }
        50% { opacity: 0.7; }
        100% { opacity: 1; }
    }
    .tool-usage {
        background-color: #e8f4fd;
        border: 1px solid #2196f3;
        border-radius: 0.25rem;
        padding: 0.5rem;
        margin: 0.25rem 0;
        font-size: 0.9rem;
    }
    .metrics-container {
        display: flex;
        justify-content: space-around;
        margin: 1rem 0;
    }
    .metric-box {
        text-align: center;
        padding: 1rem;
        border-radius: 0.5rem;
        background-color: #f8f9fa;
        border: 1px solid #dee2e6;
    }
</style>
""", unsafe_allow_html=True)


def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "agent" not in st.session_state:
        st.session_state.agent = None
    if "thread_id" not in st.session_state:
        st.session_state.thread_id = f"streamlit_session_{uuid.uuid4().hex[:8]}"
    if "streaming_response" not in st.session_state:
        st.session_state.streaming_response = ""
    if "conversation_stats" not in st.session_state:
        st.session_state.conversation_stats = {
            "total_queries": 0,
            "successful_responses": 0,
            "tool_usage_count": 0,
            "avg_response_time": 0.0
        }
    if "api_keys_set" not in st.session_state:
        st.session_state.api_keys_set = False


def check_api_keys() -> bool:
    """API í‚¤ í™•ì¸"""
    openai_key = os.getenv("OPENAI_API_KEY")
    tavily_key = os.getenv("TAVILY_API_KEY")
    
    return bool(openai_key and tavily_key and 
                openai_key != "test_openai_key_here" and 
                tavily_key != "test_tavily_key_here")


def display_api_key_setup():
    """API í‚¤ ì„¤ì • UI"""
    st.markdown('<div class="main-header">ğŸ”‘ API í‚¤ ì„¤ì •</div>', unsafe_allow_html=True)
    
    st.warning("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ ì•„ë˜ì— ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with st.form("api_keys_form"):
        st.subheader("API í‚¤ ì…ë ¥")
        
        openai_key = st.text_input(
            "OpenAI API Key",
            type="password",
            help="OpenAI Platformì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        tavily_key = st.text_input(
            "Tavily API Key", 
            type="password",
            help="Tavilyì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        submitted = st.form_submit_button("API í‚¤ ì„¤ì •")
        
        if submitted:
            if openai_key and tavily_key:
                os.environ["OPENAI_API_KEY"] = openai_key
                os.environ["TAVILY_API_KEY"] = tavily_key
                st.session_state.api_keys_set = True
                st.success("âœ… API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
            else:
                st.error("âŒ ëª¨ë“  API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # API í‚¤ ë°œê¸‰ ì•ˆë‚´
    st.markdown("---")
    st.subheader("ğŸ“‹ API í‚¤ ë°œê¸‰ ë°©ë²•")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **OpenAI API Key**
        1. [OpenAI Platform](https://platform.openai.com/api-keys) ë°©ë¬¸
        2. ê³„ì • ìƒì„± ë˜ëŠ” ë¡œê·¸ì¸
        3. API Keys ì„¹ì…˜ì—ì„œ ìƒˆ í‚¤ ìƒì„±
        4. ìƒì„±ëœ í‚¤ë¥¼ ë³µì‚¬í•˜ì—¬ ìœ„ì— ì…ë ¥
        """)
    
    with col2:
        st.markdown("""
        **Tavily API Key**
        1. [Tavily](https://tavily.com/) ë°©ë¬¸
        2. ê³„ì • ìƒì„± ë˜ëŠ” ë¡œê·¸ì¸
        3. Dashboardì—ì„œ API í‚¤ í™•ì¸
        4. í‚¤ë¥¼ ë³µì‚¬í•˜ì—¬ ìœ„ì— ì…ë ¥
        
        ğŸ’¡ **ì›” 1,000íšŒ ë¬´ë£Œ ì œê³µ**
        """)


def display_conversation_stats():
    """ëŒ€í™” í†µê³„ í‘œì‹œ"""
    stats = st.session_state.conversation_stats
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ì´ ì§ˆë¬¸ ìˆ˜",
            value=stats["total_queries"],
            delta=None
        )
    
    with col2:
        success_rate = (stats["successful_responses"] / max(stats["total_queries"], 1)) * 100
        st.metric(
            label="ì„±ê³µë¥ ",
            value=f"{success_rate:.1f}%",
            delta=None
        )
    
    with col3:
        st.metric(
            label="ë„êµ¬ ì‚¬ìš© íšŸìˆ˜",
            value=stats["tool_usage_count"],
            delta=None
        )
    
    with col4:
        st.metric(
            label="í‰ê·  ì‘ë‹µ ì‹œê°„",
            value=f"{stats['avg_response_time']:.2f}ì´ˆ",
            delta=None
        )


def display_streaming_response(response_generator: Generator, placeholder, metadata_placeholder=None):
    """ëª¨ë“  ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì§€ì›í•˜ëŠ” ì‘ë‹µ í‘œì‹œ"""
    full_response = ""
    step_data = []
    token_buffer = ""
    
    # ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    settings = st.session_state.get("stream_settings", {})
    stream_mode = settings.get("mode", "messages")
    show_metadata = settings.get("show_metadata", False)
    
    # ë‹¤ì¤‘ ëª¨ë“œì¸ì§€ í™•ì¸
    is_multi_mode = isinstance(stream_mode, list)
    
    for chunk in response_generator:
        # ë©”íƒ€ë°ì´í„°ê°€ í¬í•¨ëœ ê²½ìš° ì²˜ë¦¬
        if isinstance(chunk, dict) and "data" in chunk:
            step_info = chunk
            actual_data = chunk["data"]
            
            if show_metadata and metadata_placeholder:
                step_data.append(step_info)
                display_metadata_info(step_data, metadata_placeholder)
        else:
            actual_data = chunk
            step_info = None
        
        # ë‹¤ì¤‘ ëª¨ë“œ ì²˜ë¦¬
        if is_multi_mode:
            # (mode, data) íŠœí”Œ í˜•íƒœ
            if isinstance(actual_data, tuple) and len(actual_data) == 2:
                mode, data = actual_data
                full_response = process_mode_data(mode, data, placeholder, full_response, token_buffer)
            else:
                # ì˜¤ë¥˜ ì²˜ë¦¬
                display_error_info(actual_data, placeholder)
        else:
            # ë‹¨ì¼ ëª¨ë“œ ì²˜ë¦¬
            full_response = process_mode_data(stream_mode, actual_data, placeholder, full_response, token_buffer)
        
        time.sleep(0.05)  # ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼
    
    return full_response


def process_mode_data(mode: str, data, placeholder, current_response: str, token_buffer: str = ""):
    """ëª¨ë“œë³„ ë°ì´í„° ì²˜ë¦¬ í†µí•© í•¨ìˆ˜"""
    if mode == "values":
        return process_values_mode(data, placeholder, current_response)
    elif mode == "updates":
        return process_updates_mode(data, placeholder, current_response)
    elif mode == "debug":
        return process_debug_mode(data, placeholder, current_response)
    elif mode == "messages":
        return process_messages_mode(data, placeholder, current_response, token_buffer)
    elif mode == "custom":
        return process_custom_mode(data, placeholder, current_response)
    else:
        return current_response


def process_values_mode(data, placeholder, current_response):
    """VALUES ëª¨ë“œ ë°ì´í„° ì²˜ë¦¬"""
    if isinstance(data, dict) and "messages" in data and data["messages"]:
        last_message = data["messages"][-1]
        
        if hasattr(last_message, 'content') and last_message.content:
            response = last_message.content
            
            with placeholder.container():
                st.markdown(f"""
                <div class="streaming-message">
                    <div style="font-weight: bold; margin-bottom: 0.5rem;">
                        ğŸ”¹ VALUES ëª¨ë“œ: ì „ì²´ ìƒíƒœ ({len(data["messages"])}ê°œ ë©”ì‹œì§€)
                    </div>
                    <div>{response}</div>
                </div>
                """, unsafe_allow_html=True)
            
            return response
    
    return current_response


def process_updates_mode(data, placeholder, current_response):
    """UPDATES ëª¨ë“œ ë°ì´í„° ì²˜ë¦¬"""
    if isinstance(data, dict) and "messages" in data:
        new_messages = data["messages"]
        
        if new_messages:
            for msg in new_messages:
                if hasattr(msg, 'content') and msg.content:
                    current_response += msg.content
            
            with placeholder.container():
                st.markdown(f"""
                <div class="streaming-message">
                    <div style="font-weight: bold; margin-bottom: 0.5rem;">
                        ğŸ”¸ UPDATES ëª¨ë“œ: ì¦ë¶„ ì—…ë°ì´íŠ¸ (+{len(new_messages)}ê°œ ë©”ì‹œì§€)
                    </div>
                    <div>{current_response}</div>
                </div>
                """, unsafe_allow_html=True)
    
    return current_response


def process_debug_mode(data, placeholder, current_response):
    """DEBUG ëª¨ë“œ ë°ì´í„° ì²˜ë¦¬"""
    if isinstance(data, dict):
        # DEBUG ëª¨ë“œëŠ” ë” ìƒì„¸í•œ ì •ë³´ë¥¼ í¬í•¨
        debug_info = []
        
        if "messages" in data and data["messages"]:
            last_message = data["messages"][-1]
            if hasattr(last_message, 'content') and last_message.content:
                current_response = last_message.content
            
            debug_info.append(f"ë©”ì‹œì§€ ìˆ˜: {len(data['messages'])}")
        
        # ì¶”ê°€ ë””ë²„ê·¸ ì •ë³´ ìˆ˜ì§‘
        for key, value in data.items():
            if key not in ["messages"] and value:
                debug_info.append(f"{key}: {str(value)[:50]}...")
        
        with placeholder.container():
            st.markdown(f"""
            <div class="streaming-message">
                <div style="font-weight: bold; margin-bottom: 0.5rem;">
                    ğŸ” DEBUG ëª¨ë“œ: ìƒì„¸ ì •ë³´
                </div>
                <div style="font-size: 0.8em; color: #666; margin-bottom: 0.5rem;">
                    {' | '.join(debug_info)}
                </div>
                <div>{current_response}</div>
            </div>
            """, unsafe_allow_html=True)
    
    return current_response


def process_messages_mode(data, placeholder, current_response, token_buffer):
    """MESSAGES ëª¨ë“œ - LLM í† í° ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (ì‚¬ìš©ì ì¹œí™”ì )"""
    
    # ì—ëŸ¬ ì²˜ë¦¬ ë¨¼ì € í™•ì¸
    if isinstance(data, dict) and "error" in data:
        with placeholder.container():
            st.error(f"ğŸ”¤ ì˜¤ë¥˜: {data['error']}")
        return current_response
    
    # messages ëª¨ë“œì—ì„œëŠ” (message_chunk, metadata) íŠœí”Œì´ ë°˜í™˜ë¨
    if isinstance(data, tuple) and len(data) == 2:
        message_chunk, metadata = data
        
        # í† í° ë‚´ìš© ì¶”ì¶œ (ì‹¤ì œ AI ì‘ë‹µë§Œ)
        token_content = ""
        if hasattr(message_chunk, 'content') and message_chunk.content:
            # ë„êµ¬ ê²°ê³¼ë‚˜ ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ì œì™¸í•˜ê³  AI ì‘ë‹µë§Œ í‘œì‹œ
            content = message_chunk.content
            
            # ê¹”ë”í•œ ëª¨ë“œì—ì„œëŠ” ë„êµ¬ ê²°ê³¼ í•„í„°ë§
            settings = st.session_state.get("stream_settings", {})
            clean_mode = settings.get("clean_mode", True)
            
            if clean_mode:
                # JSON í˜•íƒœì˜ ë„êµ¬ ê²°ê³¼ëŠ” í•„í„°ë§
                if not (content.startswith('{"') and '"results"' in content):
                    token_content = content
                    current_response += token_content
            else:
                # ëª¨ë“  ë‚´ìš© í‘œì‹œ
                token_content = content
                current_response += token_content
        
        # ë©”íƒ€ë°ì´í„°ì—ì„œ ë…¸ë“œ ì •ë³´ í™•ì¸
        node_info = metadata.get("langgraph_node", "unknown") if isinstance(metadata, dict) else "unknown"
        
        # AI ì‘ë‹µë§Œ í‘œì‹œ (ë„êµ¬ ë…¸ë“œ ì œì™¸)
        if token_content and node_info != "tools":
            with placeholder.container():
                st.markdown(f"""
                <div class="streaming-message">
                    <div style="font-weight: bold; margin-bottom: 0.5rem; color: #1f77b4;">
                        ğŸ¤– AI ì‘ë‹µ ìƒì„± ì¤‘...
                    </div>
                    <div style="background: #f8f9fa; padding: 1rem; border-radius: 0.5rem; border-left: 4px solid #1f77b4; white-space: pre-wrap; line-height: 1.6;">
                        {current_response}
                    </div>
                </div>
                """, unsafe_allow_html=True)
        
        # ë„êµ¬ ì‚¬ìš© ì¤‘ì¼ ë•Œ ë³„ë„ í‘œì‹œ
        elif node_info == "tools":
            # í˜„ì¬ ë„ë©”ì¸ ì„¤ì • ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            settings = st.session_state.get("stream_settings", {})
            include_domains = settings.get("include_domains", [])
            exclude_domains = settings.get("exclude_domains", [])
            search_depth = settings.get("search_depth", "basic")
            max_results = settings.get("max_results", 5)
            
            # ë„ë©”ì¸ í•„í„°ë§ ì •ë³´ ìƒì„±
            domain_info = ""
            if include_domains:
                domain_info += f"í¬í•¨ ë„ë©”ì¸: {', '.join(include_domains[:2])}{'...' if len(include_domains) > 2 else ''} | "
            if exclude_domains:
                domain_info += f"ì œì™¸ ë„ë©”ì¸: {', '.join(exclude_domains[:2])}{'...' if len(exclude_domains) > 2 else ''} | "
            domain_info += f"ê¹Šì´: {search_depth} | ê²°ê³¼: {max_results}ê°œ"
            
            with placeholder.container():
                st.markdown(f"""
                <div class="tool-usage">
                    <div style="font-weight: bold; color: #ff9800; margin-bottom: 0.5rem;">
                        ğŸ” ì •ë³´ ê²€ìƒ‰ ì¤‘...
                    </div>
                    <div style="color: #666; font-style: italic; margin-bottom: 0.25rem;">
                        Tavily ê²€ìƒ‰ ì—”ì§„ì„ í†µí•´ ìµœì‹  ì •ë³´ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤.
                    </div>
                    <div style="font-size: 0.8em; color: #888; background: #f0f0f0; padding: 0.25rem; border-radius: 0.25rem;">
                        {domain_info}
                    </div>
                </div>
                """, unsafe_allow_html=True)
        
        return current_response
    
    # ë‹¤ë¥¸ í˜•íƒœì˜ ë©”ì‹œì§€ ì²˜ë¦¬
    elif data and hasattr(data, 'content'):
        content = data.content if data.content else ""
        
        # ê¹”ë”í•œ ëª¨ë“œ ì„¤ì • í™•ì¸
        settings = st.session_state.get("stream_settings", {})
        clean_mode = settings.get("clean_mode", True)
        
        if content:
            if clean_mode:
                # JSON í˜•íƒœì˜ ë„êµ¬ ê²°ê³¼ëŠ” ì œì™¸ (ë” ì—„ê²©í•œ í•„í„°ë§)
                is_json_tool_result = (
                    content.startswith('{"') or 
                    content.startswith("{'") or
                    ('"query"' in content and '"results"' in content) or
                    ('"url"' in content and '"title"' in content and '"content"' in content)
                )
                
                if not is_json_tool_result:
                    current_response += content
            else:
                # ëª¨ë“  ë‚´ìš© í‘œì‹œ
                current_response += content
            
            with placeholder.container():
                st.markdown(f"""
                <div class="streaming-message">
                    <div style="font-weight: bold; margin-bottom: 0.5rem; color: #1f77b4;">
                        ğŸ¤– AI ì‘ë‹µ
                    </div>
                    <div style="background: #f8f9fa; padding: 1rem; border-radius: 0.5rem; border-left: 4px solid #1f77b4; white-space: pre-wrap; line-height: 1.6;">
                        {current_response}
                    </div>
                </div>
                """, unsafe_allow_html=True)
        
        return current_response
    
    return current_response


def process_custom_mode(data, placeholder, current_response):
    """CUSTOM ëª¨ë“œ - ì»¤ìŠ¤í…€ ë°ì´í„° ì²˜ë¦¬"""
    if data:
        with placeholder.container():
            st.markdown(f"""
            <div class="streaming-message">
                <div style="font-weight: bold; margin-bottom: 0.5rem;">
                    ğŸ¯ CUSTOM ëª¨ë“œ: ì»¤ìŠ¤í…€ ë°ì´í„°
                </div>
                <div style="background: #e8f4fd; padding: 0.5rem; border-radius: 0.25rem; border-left: 4px solid #2196f3;">
                    <pre>{str(data)}</pre>
                </div>
            </div>
            """, unsafe_allow_html=True)
    
    return current_response


def display_error_info(data, placeholder):
    """ì˜¤ë¥˜ ì •ë³´ í‘œì‹œ"""
    with placeholder.container():
        st.error(f"ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {data}")


def detect_tool_usage(data, placeholder):
    """ë„êµ¬ ì‚¬ìš© ê°ì§€ (ëª¨ë“  ëª¨ë“œ ê³µí†µ)"""
    # messages ëª¨ë“œê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ë„êµ¬ ì‚¬ìš© í‘œì‹œ
    settings = st.session_state.get("stream_settings", {})
    stream_mode = settings.get("mode", "messages")
    
    if stream_mode == "messages":
        return  # messages ëª¨ë“œì—ì„œëŠ” ë³„ë„ ì²˜ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ìŠ¤í‚µ
    
    if isinstance(data, dict) and "messages" in data:
        messages = data["messages"] if isinstance(data["messages"], list) else [data["messages"]]
        
        for msg in messages:
            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                st.session_state.conversation_stats["tool_usage_count"] += 1
                
                with placeholder.container():
                    st.markdown("""
                    <div class="tool-usage">
                        ğŸ” Tavily ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤...
                    </div>
                    """, unsafe_allow_html=True)
                break


def display_metadata_info(step_data, metadata_placeholder):
    """ë©”íƒ€ë°ì´í„° ì •ë³´ í‘œì‹œ"""
    if not step_data:
        return
    
    latest_step = step_data[-1]
    
    with metadata_placeholder.container():
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ë‹¨ê³„", latest_step.get("step_number", 0))
        
        with col2:
            elapsed = latest_step.get("elapsed_time", 0)
            st.metric("ê²½ê³¼ ì‹œê°„", f"{elapsed:.2f}ì´ˆ")
        
        with col3:
            data_size = latest_step.get("data_size", 0)
            st.metric("ë°ì´í„° í¬ê¸°", f"{data_size:,} ë¬¸ì")
        
        with col4:
            mode = latest_step.get("stream_mode", "unknown")
            st.metric("ëª¨ë“œ", mode.upper())
        
        # ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© ì°¨íŠ¸
        if len(step_data) > 1:
            
            df = pd.DataFrame([
                {
                    "ë‹¨ê³„": step["step_number"],
                    "ë°ì´í„° í¬ê¸°": step["data_size"],
                    "ê²½ê³¼ ì‹œê°„": step["elapsed_time"]
                }
                for step in step_data
            ])
            
            st.line_chart(df.set_index("ë‹¨ê³„"))


def process_streaming_query(user_input: str):
    """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì¿¼ë¦¬ ì²˜ë¦¬"""
    start_time = time.time()
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({
        "role": "user",
        "content": user_input,
        "timestamp": time.strftime("%H:%M:%S")
    })
    
    # í†µê³„ ì—…ë°ì´íŠ¸
    st.session_state.conversation_stats["total_queries"] += 1
    
    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì»¨í…Œì´ë„ˆ
    response_placeholder = st.empty()
    
    try:
        # ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        stream_settings = st.session_state.get("stream_settings", {})
        stream_mode = stream_settings.get("mode", "messages")
        show_metadata = stream_settings.get("show_metadata", False)
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
        if show_metadata:
            response_generator = st.session_state.agent.stream_response_with_metadata(
                user_input,
                thread_id=st.session_state.thread_id,
                stream_mode=stream_mode
            )
        else:
            response_generator = st.session_state.agent.stream_response(
                user_input,
                thread_id=st.session_state.thread_id,
                stream_mode=stream_mode
            )
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í‘œì‹œ
        final_response = display_streaming_response(response_generator, response_placeholder)
        
        # ì‘ë‹µì´ ìˆë“  ì—†ë“  ì²˜ë¦¬ ì™„ë£Œë¡œ ê°„ì£¼
        if final_response and final_response.strip():
            response_content = final_response.strip()
        else:
            # messages ëª¨ë“œì—ì„œëŠ” í† í°ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë˜ë¯€ë¡œ ë¹ˆ ì‘ë‹µë„ ì •ìƒ
            response_content = "ì‘ë‹µì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        
        # ìµœì¢… ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({
            "role": "assistant", 
            "content": response_content,
            "timestamp": time.strftime("%H:%M:%S")
        })
        
        # ì„±ê³µ í†µê³„ ì—…ë°ì´íŠ¸
        st.session_state.conversation_stats["successful_responses"] += 1
        
        # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        response_time = time.time() - start_time
        current_avg = st.session_state.conversation_stats["avg_response_time"]
        total_queries = st.session_state.conversation_stats["total_queries"]
        
        # í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
        new_avg = ((current_avg * (total_queries - 1)) + response_time) / total_queries
        st.session_state.conversation_stats["avg_response_time"] = new_avg
        
        # ìµœì¢… ì™„ë£Œ ë©”ì‹œì§€ í‘œì‹œ (messages ëª¨ë“œì—ì„œëŠ” ì´ë¯¸ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë¨)
        if stream_mode != "messages":
            response_placeholder.empty()
            
    except Exception as e:
        error_msg = f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        
        st.session_state.messages.append({
            "role": "error",
            "content": error_msg,
            "timestamp": time.strftime("%H:%M:%S")
        })
        
        response_placeholder.empty()


def display_advanced_sidebar():
    """ì‚¬ì´ë“œë°” í‘œì‹œ"""
    with st.sidebar:
        st.markdown('<div class="main-header">ğŸ¤– PAI Web Agent</div>', unsafe_allow_html=True)
        
        # API í‚¤ ìƒíƒœ í‘œì‹œ
        st.subheader("ğŸ” API ìƒíƒœ")
        if check_api_keys():
            st.success("âœ… API í‚¤ ì„¤ì •ë¨")
        else:
            st.error("ğŸ”‘ API í‚¤ í•„ìš”")
            if st.button("ğŸ”‘ API í‚¤ ì„¤ì •í•˜ê¸°", use_container_width=True):
                st.session_state.show_api_setup = True
                st.rerun()
        
        # ì—ì´ì „íŠ¸ ì„¤ì •
        st.subheader("ğŸ”§ ì—ì´ì „íŠ¸ ì„¤ì •")
        
        # ëª¨ë¸ ì„ íƒ
        model_options = ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"]
        selected_model = st.selectbox(
            "ëª¨ë¸ ì„ íƒ",
            model_options,
            index=0,
            help="ì‚¬ìš©í•  OpenAI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”"
        )
        
        # ì˜¨ë„ ì„¤ì •
        temperature = st.slider(
            "ì°½ì˜ì„± ìˆ˜ì¤€ (Temperature)",
            min_value=0.0,
            max_value=1.0,
            value=0.1,
            step=0.1,
            help="ë†’ì„ìˆ˜ë¡ ë” ì°½ì˜ì ì¸ ì‘ë‹µ"
        )
        
        
        # ê²€ìƒ‰ ì„¤ì •
        st.subheader("ğŸ” ê²€ìƒ‰ ì„¤ì •")
        
        search_depth = st.selectbox(
            "ê²€ìƒ‰ ê¹Šì´",
            ["basic", "advanced"],
            index=0,
            help="advancedëŠ” ë” ì •í™•í•˜ì§€ë§Œ ë¹„ìš©ì´ 2ë°°"
        )
        
        max_results = st.slider(
            "ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜",
            min_value=1,
            max_value=10,
            value=5,
            help="ë” ë§ì€ ê²°ê³¼ëŠ” ë” ì •í™•í•˜ì§€ë§Œ ëŠë¦¼"
        )
        
        # ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • (messages ëª¨ë“œ ê³ ì •)
        st.subheader("ğŸ”„ ìŠ¤íŠ¸ë¦¬ë° ì„¤ì •")
        st.info("ğŸ’¬ **Messages ëª¨ë“œ**: ì‹¤ì‹œê°„ í† í° ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë¹ ë¥¸ ì‘ë‹µ ì œê³µ")
        stream_mode = "messages"  # ê³ ì •
        
        show_metadata = st.checkbox(
            "ë©”íƒ€ë°ì´í„° í‘œì‹œ",
            value=False,
            help="ë‹¨ê³„ë³„ ì‹¤í–‰ ì‹œê°„, ë°ì´í„° í¬ê¸° ë“± ìƒì„¸ ì •ë³´ í‘œì‹œ"
        )
        
        clean_mode = st.checkbox(
            "ê¹”ë”í•œ ëª¨ë“œ",
            value=True,
            help="ë„êµ¬ ê²°ê³¼ë‚˜ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ìˆ¨ê¸°ê³  AI ì‘ë‹µë§Œ í‘œì‹œ"
        )
        
        # ë„ë©”ì¸ í•„í„°ë§ ìƒíƒœ í‘œì‹œ
        st.subheader("ğŸŒ ë„ë©”ì¸ í•„í„°ë§ ìƒíƒœ")
        
        # í˜„ì¬ ì„¤ì •ëœ ë„ë©”ì¸ í‘œì‹œ (tools.pyì—ì„œ í•˜ë“œì½”ë”©ëœ ê°’)
        current_include_domains = ["*.go.kr", "*.or.kr"]
        current_exclude_domains = []
        
        st.info(f"""
        **í˜„ì¬ ì ìš©ëœ ë„ë©”ì¸ í•„í„°ë§:**
        - ğŸ›ï¸ **í¬í•¨ ë„ë©”ì¸**: {', '.join(current_include_domains)}
        - ğŸš« **ì œì™¸ ë„ë©”ì¸**: {'ì—†ìŒ' if not current_exclude_domains else ', '.join(current_exclude_domains)}
        
        """)
        
        
        
        # ì„¸ì…˜ ìƒíƒœì— ì„¤ì • ì €ì¥
        if "stream_settings" not in st.session_state:
            st.session_state.stream_settings = {}
        
        st.session_state.stream_settings.update({
            "mode": stream_mode,
            "show_metadata": show_metadata,
            "clean_mode": clean_mode,
            "search_depth": search_depth,
            "max_results": max_results,
            "include_domains": current_include_domains,
            "exclude_domains": current_exclude_domains
        })
        
        # ì—ì´ì „íŠ¸ ì¬ì´ˆê¸°í™”
        if st.button("ğŸ”„ ì„¤ì • ì ìš©", use_container_width=True):
            try:
                st.session_state.agent = SupervisedAgent(
                    model_name=selected_model,
                    temperature=temperature,
                )
                st.success("âœ… ì„¤ì •ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")
            except Exception as e:
                st.error(f"âŒ ì„¤ì • ì ìš© ì‹¤íŒ¨: {str(e)}")
        
        st.markdown("---")
        
        # ëŒ€í™” ê´€ë¦¬
        st.subheader("ğŸ’¬ ëŒ€í™” ê´€ë¦¬")
        
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì‚­ì œ", use_container_width=True):
            # ìƒˆë¡œìš´ thread_id ìƒì„±ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
            st.session_state.thread_id = f"streamlit_session_{uuid.uuid4().hex[:8]}"
            st.session_state.messages = []
            st.session_state.conversation_stats = {
                "total_queries": 0,
                "successful_responses": 0,
                "tool_usage_count": 0,
                "avg_response_time": 0.0
            }
            st.success("âœ… ëŒ€í™” ê¸°ë¡ì´ ì™„ì „íˆ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
        
        # ëŒ€í™” ë‚´ë³´ë‚´ê¸°
        if st.session_state.messages:
            export_format = st.selectbox("ë‚´ë³´ë‚´ê¸° í˜•ì‹", ["TXT", "JSON", "CSV"])
            
            if export_format == "TXT":
                export_data = "\n".join([
                    f"[{msg.get('timestamp', 'N/A')}] {msg['role'].upper()}: {msg['content']}"
                    for msg in st.session_state.messages
                ])
                file_ext = "txt"
                mime_type = "text/plain"
            
            elif export_format == "JSON":
                export_data = json.dumps(st.session_state.messages, ensure_ascii=False, indent=2)
                file_ext = "json"
                mime_type = "application/json"
            
            else:  # CSV
                output = io.StringIO()
                writer = csv.writer(output)
                writer.writerow(["timestamp", "role", "content"])
                for msg in st.session_state.messages:
                    writer.writerow([msg.get('timestamp', 'N/A'), msg['role'], msg['content']])
                export_data = output.getvalue()
                file_ext = "csv"
                mime_type = "text/csv"
            
            st.download_button(
                label=f"ğŸ’¾ {export_format} ë‹¤ìš´ë¡œë“œ",
                data=export_data,
                file_name=f"chat_history_{st.session_state.thread_id}.{file_ext}",
                mime=mime_type,
                use_container_width=True
            )


def display_advanced_chat():
    """ê³ ê¸‰ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤"""
    # ëŒ€í™” í†µê³„ í‘œì‹œ
    st.subheader("ğŸ“Š ëŒ€í™” í†µê³„")
    display_conversation_stats()
    
    st.markdown("---")
    
    # ì±„íŒ… ê¸°ë¡
    st.subheader("ğŸ’¬ ëŒ€í™” ê¸°ë¡")
    
    # ì±„íŒ… ì»¨í…Œì´ë„ˆ
    chat_container = st.container()
    
    with chat_container:
        if not st.session_state.messages:
            st.info("ğŸ‘‹ ì•ˆë…•í•˜ì„¸ìš”! ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        for message in st.session_state.messages:
            role = message["role"]
            content = message["content"]
            timestamp = message.get("timestamp", "")
            
            if role == "user":
                st.chat_message("user").write(f"**[{timestamp}]** {content}")
            elif role == "assistant":
                st.chat_message("assistant").write(f"**[{timestamp}]** {content}")
            else:  # error
                st.chat_message("assistant").error(f"**[{timestamp}]** {content}")
    
    # ì…ë ¥ ì˜ì—­
    st.markdown("---")
    
    # ë¹ ë¥¸ ì§ˆë¬¸ ë²„íŠ¼
    st.subheader("âš¡ ë¹ ë¥¸ ì§ˆë¬¸")
    
    col1, col2, col3 = st.columns(3)
    
    quick_questions = [
        "2025ë…„ ëŒ€í•œë¯¼êµ­ ì˜ˆì‚° ê·œëª¨ëŠ”?",
        "ìµœê·¼ í†µê³„ì²­ ë°œí‘œ ì£¼ìš” ì§€í‘œëŠ”?",
        "ì •ë¶€ ì •ì±… ìµœì‹  ë™í–¥ì€?",
        "ê³µê³µê¸°ê´€ ì±„ìš© ì •ë³´ëŠ”?",
        "ì§€ë°©ìì¹˜ë‹¨ì²´ ì¬ì • í˜„í™©ì€?",
        "êµ­ê°€í†µê³„í¬í„¸ ìµœì‹  ë°ì´í„°ëŠ”?"
    ]
    
    for i, question in enumerate(quick_questions):
        col = [col1, col2, col3][i % 3]
        with col:
            if st.button(question, key=f"quick_{i}", use_container_width=True):
                process_streaming_query(question)
                st.rerun()
    
    # ì‚¬ìš©ì ì…ë ¥
    st.subheader("âœï¸ ì§ˆë¬¸ ì…ë ¥")
    
    user_input = st.text_area(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
        placeholder="ì˜ˆ: ëŒ€êµ¬ê´‘ì—­ì‹œ 2025ë…„ ì¬ì • í˜„í™©ì€? ë˜ëŠ” í†µê³„ì²­ ìµœê·¼ ì¸êµ¬ í†µê³„ëŠ”?",
        height=100,
        key="user_input"
    )
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        if st.button("ğŸš€ ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡", use_container_width=True, type="primary"):
            if user_input.strip():
                process_streaming_query(user_input.strip())
                st.rerun()
            else:
                st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with col2:
        if st.button("ğŸ”„ ì…ë ¥ ì´ˆê¸°í™”", use_container_width=True):
            st.session_state.user_input = ""
            st.rerun()
    

def main():
    """ê³ ê¸‰ ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    initialize_session_state()
    
    # API í‚¤ ì„¤ì • ìƒíƒœ í™•ì¸
    if "show_api_setup" not in st.session_state:
        st.session_state.show_api_setup = False
    
    # API í‚¤ í™•ì¸
    if not check_api_keys() and not st.session_state.api_keys_set:
        if not st.session_state.show_api_setup:
            st.session_state.show_api_setup = True
        display_api_key_setup()
        return
    
    # ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
    if st.session_state.agent is None:
        try:
            with st.spinner("ğŸ¤– ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘..."):
                st.session_state.agent = create_agent()
            st.success("âœ… ì—ì´ì „íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
        except Exception as e:
            st.error(f"âŒ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            st.stop()
    
    # ì‚¬ì´ë“œë°” í‘œì‹œ
    display_advanced_sidebar()
    
    # ë©”ì¸ í—¤ë”
    st.markdown('<div class="main-header">ğŸ¤– PAI Web Agent</div>', unsafe_allow_html=True)
    
    st.markdown("""
    ### ğŸŒŸ ì£¼ìš” ê¸°ëŠ¥
    - **ğŸ›ï¸ ê³µê³µê¸°ê´€ ì •ë³´ íŠ¹í™”**: *.go.kr, *.or.kr ë„ë©”ì¸ ìš°ì„  ê²€ìƒ‰
    - **ğŸ” ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰**: Tavily APIë¡œ ìµœì‹  ì •ë¶€/ê³µê³µê¸°ê´€ ì •ë³´ ìˆ˜ì§‘
    - **ğŸ’¬ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ**: ì‘ë‹µ ìƒì„± ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸
    - **ğŸ“Š ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´**: ê³µì‹ ì‚¬ì´íŠ¸ ìš°ì„ , ê°œì¸ ë¸”ë¡œê·¸/SNS ì œì™¸
    - **ğŸŒ ë„ë©”ì¸ í•„í„°ë§**: ì •ë¶€ê¸°ê´€, ê³µê³µê¸°ê´€ ì‚¬ì´íŠ¸ë§Œ ê²€ìƒ‰ ê°€ëŠ¥
    - **ğŸ¯ ê³µê³µì •ë³´ ë¹ ë¥¸ ì§ˆë¬¸**: ì˜ˆì‚°, í†µê³„, ì •ì±… ë“± ë¯¸ë¦¬ ì¤€ë¹„ëœ ì§ˆë¬¸
    """)
    
    # ê³ ê¸‰ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    display_advanced_chat()


if __name__ == "__main__":
    main()