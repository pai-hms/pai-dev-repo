import streamlit as st
import os
import time
import asyncio
import uuid
import json
import csv
import io
import pandas as pd
from typing import Dict, Any, List, Generator
from agent import create_agent, SupervisedAgent
from tools import create_tavily_tool

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="PAI Web Agent",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ê³ ê¸‰ CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        margin-bottom: 2rem;
        background: linear-gradient(90deg, #1f77b4, #ff7f0e);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    .chat-container {
        max-height: 600px;
        overflow-y: auto;
        padding: 1rem;
        border: 1px solid #e0e0e0;
        border-radius: 0.5rem;
        background-color: #fafafa;
    }
    .streaming-message {
        background-color: #fff3e0;
        border-left: 4px solid #ff9800;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
        animation: pulse 1.5s infinite;
    }
    @keyframes pulse {
        0% { opacity: 1; }
        50% { opacity: 0.7; }
        100% { opacity: 1; }
    }
    .tool-usage {
        background-color: #e8f4fd;
        border: 1px solid #2196f3;
        border-radius: 0.25rem;
        padding: 0.5rem;
        margin: 0.25rem 0;
        font-size: 0.9rem;
    }
    .metrics-container {
        display: flex;
        justify-content: space-around;
        margin: 1rem 0;
    }
    .metric-box {
        text-align: center;
        padding: 1rem;
        border-radius: 0.5rem;
        background-color: #f8f9fa;
        border: 1px solid #dee2e6;
    }
    .settings-monitor {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .settings-changed-alert {
        background-color: #fff3cd;
        border-left: 4px solid #ffc107;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
        animation: shake 0.5s;
    }
    @keyframes shake {
        0%, 100% { transform: translateX(0); }
        25% { transform: translateX(-5px); }
        75% { transform: translateX(5px); }
    }
    .settings-applied {
        background-color: #d4edda;
        border-left: 4px solid #28a745;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)


def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "agent" not in st.session_state:
        st.session_state.agent = None
    if "thread_id" not in st.session_state:
        st.session_state.thread_id = f"streamlit_session_{uuid.uuid4().hex[:8]}"
    if "streaming_response" not in st.session_state:
        st.session_state.streaming_response = ""
    if "conversation_stats" not in st.session_state:
        st.session_state.conversation_stats = {
            "total_queries": 0,
            "successful_responses": 0,
            "tool_usage_count": 0,
            "avg_response_time": 0.0,
            "avg_first_token_time": 0.0
        }
    if "api_keys_set" not in st.session_state:
        st.session_state.api_keys_set = False
    if "current_agent_settings" not in st.session_state:
        st.session_state.current_agent_settings = {
            "model": "gpt-4.1-mini",
            "temperature": 0.1,
            "search_depth": "basic",
            "max_results": 5,
            "include_domains": ["*.go.kr", "*.or.kr"],
            "exclude_domains": []
        }
    if "settings_changed" not in st.session_state:
        st.session_state.settings_changed = False


def check_api_keys() -> bool:
    """API í‚¤ í™•ì¸"""
    openai_key = os.getenv("OPENAI_API_KEY")
    tavily_key = os.getenv("TAVILY_API_KEY")
    
    return bool(openai_key and tavily_key and 
                openai_key != "test_openai_key_here" and 
                tavily_key != "test_tavily_key_here")


def display_api_key_setup():
    """API í‚¤ ì„¤ì • UI"""
    st.markdown('<div class="main-header">ğŸ”‘ API í‚¤ ì„¤ì •</div>', unsafe_allow_html=True)
    
    st.warning("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ ì•„ë˜ì— ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with st.form("api_keys_form"):
        st.subheader("API í‚¤ ì…ë ¥")
        
        openai_key = st.text_input(
            "OpenAI API Key",
            type="password",
            help="OpenAI Platformì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        tavily_key = st.text_input(
            "Tavily API Key", 
            type="password",
            help="Tavilyì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        submitted = st.form_submit_button("API í‚¤ ì„¤ì •")
        
        if submitted:
            if openai_key and tavily_key:
                os.environ["OPENAI_API_KEY"] = openai_key
                os.environ["TAVILY_API_KEY"] = tavily_key
                st.session_state.api_keys_set = True
                st.success("âœ… API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
            else:
                st.error("âŒ ëª¨ë“  API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # API í‚¤ ë°œê¸‰ ì•ˆë‚´
    st.markdown("---")
    st.subheader("ğŸ“‹ API í‚¤ ë°œê¸‰ ë°©ë²•")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **OpenAI API Key**
        1. [OpenAI Platform](https://platform.openai.com/api-keys) ë°©ë¬¸
        2. ê³„ì • ìƒì„± ë˜ëŠ” ë¡œê·¸ì¸
        3. API Keys ì„¹ì…˜ì—ì„œ ìƒˆ í‚¤ ìƒì„±
        4. ìƒì„±ëœ í‚¤ë¥¼ ë³µì‚¬í•˜ì—¬ ìœ„ì— ì…ë ¥
        """)
    
    with col2:
        st.markdown("""
        **Tavily API Key**
        1. [Tavily](https://tavily.com/) ë°©ë¬¸
        2. ê³„ì • ìƒì„± ë˜ëŠ” ë¡œê·¸ì¸
        3. Dashboardì—ì„œ API í‚¤ í™•ì¸
        4. í‚¤ë¥¼ ë³µì‚¬í•˜ì—¬ ìœ„ì— ì…ë ¥
        
        ğŸ’¡ **ì›” 1,000íšŒ ë¬´ë£Œ ì œê³µ**
        """)


def display_conversation_stats():
    """ëŒ€í™” í†µê³„ í‘œì‹œ"""
    stats = st.session_state.conversation_stats
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ì´ ì§ˆë¬¸ ìˆ˜",
            value=stats["total_queries"],
            delta=None
        )
    
    with col2:
        success_rate = (stats["successful_responses"] / max(stats["total_queries"], 1)) * 100
        st.metric(
            label="ì„±ê³µë¥ ",
            value=f"{success_rate:.1f}%",
            delta=None
        )
    
    with col3:
        st.metric(
            label="ë„êµ¬ ì‚¬ìš© íšŸìˆ˜",
            value=stats["tool_usage_count"],
            delta=None
        )
    
    with col4:
        st.metric(
            label="í‰ê·  ì‘ë‹µ ì‹œê°„",
            value=f"{stats['avg_response_time']:.2f}ì´ˆ",
            delta=None
        )
    
    # ë‘ ë²ˆì§¸ ì¤„ í†µê³„
    col5, col6 = st.columns(2)
    
    with col5:
        st.metric(
            label="í‰ê·  ì²« í† í° ì‹œê°„",
            value=f"{stats['avg_first_token_time']:.2f}ì´ˆ",
            delta=None,
            help="ì§ˆë¬¸ í›„ ì²« ë²ˆì§¸ ì‘ë‹µì´ ë‚˜íƒ€ë‚˜ê¸°ê¹Œì§€ì˜ ì‹œê°„"
        )


def display_current_settings():
    """í˜„ì¬ ì ìš©ëœ ì„¤ì • ì‹¤ì‹œê°„ í‘œì‹œ"""
    settings = st.session_state.current_agent_settings
    
    # ì„¤ì • ë³€ê²½ ì—¬ë¶€ì— ë”°ë¥¸ ìŠ¤íƒ€ì¼ë§
    if st.session_state.settings_changed:
        status_class = "settings-changed-alert"
        status_icon = "âš ï¸"
        status_text = "ì„¤ì •ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ 'ğŸ”„ ì„¤ì • ì ìš©' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë³€ê²½ì‚¬í•­ì„ ì ìš©í•˜ì„¸ìš”."
    else:
        status_class = "settings-applied"
        status_icon = "âœ…"
        status_text = "ìµœì‹  ì„¤ì •ì´ ì ìš©ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ëª¨ë“  ê²€ìƒ‰ì´ ì´ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤."
    
    st.markdown(f"""
    <div class="{status_class}">
        <h3>{status_icon} ì„¤ì • ìƒíƒœ</h3>
        <p>{status_text}</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ìƒì„¸ ì„¤ì • ì •ë³´ë¥¼ ì¹´ë“œ í˜•íƒœë¡œ í‘œì‹œ
    st.markdown("### âš™ï¸ í˜„ì¬ ì ìš©ëœ ì„¤ì •")
    
    # ìƒì„¸ ì„¤ì • ì •ë³´
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**ğŸ¤– ëª¨ë¸ ì„¤ì •**")
        st.info(f"""
        - ëª¨ë¸: `{settings['model']}`
        - ì°½ì˜ì„±: `{settings['temperature']}`
        """)
        
        st.markdown("**ğŸ” ê²€ìƒ‰ ì„¤ì •**")
        st.info(f"""
        - ê²€ìƒ‰ ê¹Šì´: `{settings['search_depth'].upper()}`
        - ìµœëŒ€ ê²°ê³¼ ìˆ˜: `{settings['max_results']}ê°œ`
        """)
    
    with col2:
        st.markdown("**ğŸŒ ë„ë©”ì¸ í•„í„°ë§**")
        
        # í¬í•¨ ë„ë©”ì¸
        include_str = "ì œí•œ ì—†ìŒ"
        if settings['include_domains']:
            include_str = "<br/>".join([f"âœ… <code>{d}</code>" for d in settings['include_domains'][:5]])
            if len(settings['include_domains']) > 5:
                include_str += f"<br/>... ì™¸ {len(settings['include_domains']) - 5}ê°œ"
        
        # ì œì™¸ ë„ë©”ì¸
        exclude_str = "ì—†ìŒ"
        if settings['exclude_domains']:
            exclude_str = "<br/>".join([f"âŒ <code>{d}</code>" for d in settings['exclude_domains'][:5]])
            if len(settings['exclude_domains']) > 5:
                exclude_str += f"<br/>... ì™¸ {len(settings['exclude_domains']) - 5}ê°œ"
        
        st.markdown(f"""
        <div style="background-color: #e8f5e9; padding: 1rem; border-radius: 0.5rem; border-left: 4px solid #4caf50;">
            <strong>í¬í•¨ ë„ë©”ì¸:</strong><br/>
            {include_str}
            <br/><br/>
            <strong>ì œì™¸ ë„ë©”ì¸:</strong><br/>
            {exclude_str}
        </div>
        """, unsafe_allow_html=True)


def display_streaming_response(response_generator: Generator, placeholder, metadata_placeholder=None, first_token_callback=None):
    """ëª¨ë“  ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì§€ì›í•˜ëŠ” ì‘ë‹µ í‘œì‹œ"""
    full_response = ""
    step_data = []
    token_buffer = ""
    first_token_recorded = False  # ì²« í† í° ê¸°ë¡ ì—¬ë¶€
    
    # ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    settings = st.session_state.get("stream_settings", {})
    stream_mode = settings.get("mode", "messages")
    show_metadata = settings.get("show_metadata", False)
    
    # ë‹¤ì¤‘ ëª¨ë“œì¸ì§€ í™•ì¸
    is_multi_mode = isinstance(stream_mode, list)
    
    for chunk in response_generator:
        # ë©”íƒ€ë°ì´í„°ê°€ í¬í•¨ëœ ê²½ìš° ì²˜ë¦¬
        if isinstance(chunk, dict) and "data" in chunk:
            step_info = chunk
            actual_data = chunk["data"]
            
            if show_metadata and metadata_placeholder:
                step_data.append(step_info)
                display_metadata_info(step_data, metadata_placeholder)
        else:
            actual_data = chunk
            step_info = None
        
        # ë‹¤ì¤‘ ëª¨ë“œ ì²˜ë¦¬
        if is_multi_mode:
            # (mode, data) íŠœí”Œ í˜•íƒœ
            if isinstance(actual_data, tuple) and len(actual_data) == 2:
                mode, data = actual_data
                full_response = process_mode_data(mode, data, placeholder, full_response, token_buffer, first_token_callback)
            else:
                # ì˜¤ë¥˜ ì²˜ë¦¬
                display_error_info(actual_data, placeholder)
        else:
            # ë‹¨ì¼ ëª¨ë“œ ì²˜ë¦¬
            full_response = process_mode_data(stream_mode, actual_data, placeholder, full_response, token_buffer, first_token_callback)
        
        time.sleep(0.05)  # ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼
    
    return full_response


def process_mode_data(mode: str, data, placeholder, current_response: str, token_buffer: str = "", first_token_callback=None):
    """ëª¨ë“œë³„ ë°ì´í„° ì²˜ë¦¬ í†µí•© í•¨ìˆ˜"""
    if mode == "values":
        return process_values_mode(data, placeholder, current_response)
    elif mode == "updates":
        return process_updates_mode(data, placeholder, current_response)
    elif mode == "debug":
        return process_debug_mode(data, placeholder, current_response)
    elif mode == "messages":
        return process_messages_mode(data, placeholder, current_response, token_buffer, first_token_callback)
    elif mode == "custom":
        return process_custom_mode(data, placeholder, current_response)
    else:
        return current_response


def process_values_mode(data, placeholder, current_response):
    """VALUES ëª¨ë“œ ë°ì´í„° ì²˜ë¦¬"""
    if isinstance(data, dict) and "messages" in data and data["messages"]:
        last_message = data["messages"][-1]
        
        if hasattr(last_message, 'content') and last_message.content:
            response = last_message.content
            
            with placeholder.container():
                st.markdown(f"""
                <div class="streaming-message">
                    <div style="font-weight: bold; margin-bottom: 0.5rem;">
                        ğŸ”¹ VALUES ëª¨ë“œ: ì „ì²´ ìƒíƒœ ({len(data["messages"])}ê°œ ë©”ì‹œì§€)
                    </div>
                    <div>{response}</div>
                </div>
                """, unsafe_allow_html=True)
            
            return response
    
    return current_response


def process_updates_mode(data, placeholder, current_response):
    """UPDATES ëª¨ë“œ ë°ì´í„° ì²˜ë¦¬"""
    if isinstance(data, dict) and "messages" in data:
        new_messages = data["messages"]
        
        if new_messages:
            for msg in new_messages:
                if hasattr(msg, 'content') and msg.content:
                    current_response += msg.content
            
            with placeholder.container():
                st.markdown(f"""
                <div class="streaming-message">
                    <div style="font-weight: bold; margin-bottom: 0.5rem;">
                        ğŸ”¸ UPDATES ëª¨ë“œ: ì¦ë¶„ ì—…ë°ì´íŠ¸ (+{len(new_messages)}ê°œ ë©”ì‹œì§€)
                    </div>
                    <div>{current_response}</div>
                </div>
                """, unsafe_allow_html=True)
    
    return current_response


def process_debug_mode(data, placeholder, current_response):
    """DEBUG ëª¨ë“œ ë°ì´í„° ì²˜ë¦¬"""
    if isinstance(data, dict):
        # DEBUG ëª¨ë“œëŠ” ë” ìƒì„¸í•œ ì •ë³´ë¥¼ í¬í•¨
        debug_info = []
        
        if "messages" in data and data["messages"]:
            last_message = data["messages"][-1]
            if hasattr(last_message, 'content') and last_message.content:
                current_response = last_message.content
            
            debug_info.append(f"ë©”ì‹œì§€ ìˆ˜: {len(data['messages'])}")
        
        # ì¶”ê°€ ë””ë²„ê·¸ ì •ë³´ ìˆ˜ì§‘
        for key, value in data.items():
            if key not in ["messages"] and value:
                debug_info.append(f"{key}: {str(value)[:50]}...")
        
        with placeholder.container():
            st.markdown(f"""
            <div class="streaming-message">
                <div style="font-weight: bold; margin-bottom: 0.5rem;">
                    ğŸ” DEBUG ëª¨ë“œ: ìƒì„¸ ì •ë³´
                </div>
                <div style="font-size: 0.8em; color: #666; margin-bottom: 0.5rem;">
                    {' | '.join(debug_info)}
                </div>
                <div>{current_response}</div>
            </div>
            """, unsafe_allow_html=True)
    
    return current_response


def process_messages_mode(data, placeholder, current_response, token_buffer, first_token_callback=None):
    """MESSAGES ëª¨ë“œ - LLM í† í° ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (ì‚¬ìš©ì ì¹œí™”ì )"""
    
    # ì—ëŸ¬ ì²˜ë¦¬ ë¨¼ì € í™•ì¸
    if isinstance(data, dict) and "error" in data:
        with placeholder.container():
            st.error(f"ğŸ”¤ ì˜¤ë¥˜: {data['error']}")
        return current_response
    
    # messages ëª¨ë“œì—ì„œëŠ” (message_chunk, metadata) íŠœí”Œì´ ë°˜í™˜ë¨
    if isinstance(data, tuple) and len(data) == 2:
        message_chunk, metadata = data
        
        # í† í° ë‚´ìš© ì¶”ì¶œ (ì‹¤ì œ AI ì‘ë‹µë§Œ)
        token_content = ""
        if hasattr(message_chunk, 'content') and message_chunk.content:
            # ë„êµ¬ ê²°ê³¼ë‚˜ ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ì œì™¸í•˜ê³  AI ì‘ë‹µë§Œ í‘œì‹œ
            content = message_chunk.content
            
            # ê¹”ë”í•œ ëª¨ë“œì—ì„œëŠ” ë„êµ¬ ê²°ê³¼ í•„í„°ë§
            settings = st.session_state.get("stream_settings", {})
            clean_mode = settings.get("clean_mode", True)
            
            if clean_mode:
                # JSON í˜•íƒœì˜ ë„êµ¬ ê²°ê³¼ëŠ” í•„í„°ë§
                if not (content.startswith('{"') and '"results"' in content):
                    token_content = content
                    current_response += token_content
            else:
                # ëª¨ë“  ë‚´ìš© í‘œì‹œ
                token_content = content
                current_response += token_content
        
        # ë©”íƒ€ë°ì´í„°ì—ì„œ ë…¸ë“œ ì •ë³´ í™•ì¸
        node_info = metadata.get("langgraph_node", "unknown") if isinstance(metadata, dict) else "unknown"
        
        # ì²« í† í° ê°ì§€ ë° ì½œë°± í˜¸ì¶œ
        if token_content and first_token_callback and not hasattr(first_token_callback, '_called'):
            first_token_callback()
            first_token_callback._called = True  # ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€
        
        # ë„êµ¬ ì‚¬ìš© ê°ì§€ ë° ì¹´ìš´íŠ¸ (ì¤‘ë³µ ë°©ì§€)
        if hasattr(message_chunk, 'tool_calls') and message_chunk.tool_calls:
            # ì´ë¯¸ ì¹´ìš´íŠ¸ëœ ë„êµ¬ í˜¸ì¶œì¸ì§€ í™•ì¸
            if "counted_tool_calls" not in st.session_state:
                st.session_state.counted_tool_calls = set()
            
            # ë„êµ¬ í˜¸ì¶œ ID ìƒì„± (ë©”ì‹œì§€ ID + ë„êµ¬ ì´ë¦„)
            tool_call_id = f"{getattr(message_chunk, 'id', 'unknown')}_{message_chunk.tool_calls[0].get('name', 'unknown')}"
            
            if tool_call_id not in st.session_state.counted_tool_calls:
                st.session_state.conversation_stats["tool_usage_count"] += 1
                st.session_state.counted_tool_calls.add(tool_call_id)
        
        # AI ì‘ë‹µë§Œ í‘œì‹œ (ë„êµ¬ ë…¸ë“œ ì œì™¸)
        if token_content and node_info != "tools":
            with placeholder.container():
                st.markdown(f"""
                <div class="streaming-message">
                    <div style="font-weight: bold; margin-bottom: 0.5rem; color: #1f77b4;">
                        ğŸ¤– AI ì‘ë‹µ ìƒì„± ì¤‘...
                    </div>
                    <div style="background: #f8f9fa; padding: 1rem; border-radius: 0.5rem; border-left: 4px solid #1f77b4; white-space: pre-wrap; line-height: 1.6;">
                        {current_response}
                    </div>
                </div>
                """, unsafe_allow_html=True)
        
        # ë„êµ¬ ì‚¬ìš© ì¤‘ì¼ ë•Œ ë³„ë„ í‘œì‹œ
        elif node_info == "tools":
            # í˜„ì¬ ì ìš©ëœ ì„¤ì • ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            current_settings = st.session_state.get("current_agent_settings", {})
            include_domains = current_settings.get("include_domains", ["*.go.kr", "*.or.kr"])
            exclude_domains = current_settings.get("exclude_domains", [])
            search_depth = current_settings.get("search_depth", "basic")
            max_results = current_settings.get("max_results", 5)
            
            # ë„ë©”ì¸ í•„í„°ë§ ì •ë³´ ìƒì„±
            domain_info_parts = []
            
            if include_domains:
                domain_list = ", ".join(include_domains[:3])
                if len(include_domains) > 3:
                    domain_list += f" ì™¸ {len(include_domains) - 3}ê°œ"
                domain_info_parts.append(f"í¬í•¨: {domain_list}")
            
            if exclude_domains:
                domain_list = ", ".join(exclude_domains[:3])
                if len(exclude_domains) > 3:
                    domain_list += f" ì™¸ {len(exclude_domains) - 3}ê°œ"
                domain_info_parts.append(f"ì œì™¸: {domain_list}")
            
            domain_info_parts.append(f"ê¹Šì´: {search_depth.upper()}")
            domain_info_parts.append(f"ê²°ê³¼ ìˆ˜: {max_results}ê°œ")
            
            domain_info = " | ".join(domain_info_parts)
            
            with placeholder.container():
                st.markdown(f"""
                <div class="tool-usage">
                    <div style="font-weight: bold; color: #ff9800; margin-bottom: 0.5rem;">
                        ğŸ” ì •ë³´ ê²€ìƒ‰ ì¤‘...
                    </div>
                    <div style="color: #666; font-style: italic; margin-bottom: 0.5rem;">
                        Tavily ê²€ìƒ‰ ì—”ì§„ì„ í†µí•´ ìµœì‹  ì •ë³´ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤.
                    </div>
                    <div style="font-size: 0.85em; color: #555; background: #e8f5e9; padding: 0.5rem; border-radius: 0.25rem; border-left: 3px solid #4caf50;">
                        <strong>ì ìš©ëœ ê²€ìƒ‰ ì„¤ì •:</strong><br/>
                        {domain_info}
                    </div>
                </div>
                """, unsafe_allow_html=True)
        
        return current_response
    
    # ë‹¤ë¥¸ í˜•íƒœì˜ ë©”ì‹œì§€ ì²˜ë¦¬
    elif data and hasattr(data, 'content'):
        content = data.content if data.content else ""
        
        # ê¹”ë”í•œ ëª¨ë“œ ì„¤ì • í™•ì¸
        settings = st.session_state.get("stream_settings", {})
        clean_mode = settings.get("clean_mode", True)
        
        if content:
            if clean_mode:
                # JSON í˜•íƒœì˜ ë„êµ¬ ê²°ê³¼ëŠ” ì œì™¸ (ë” ì—„ê²©í•œ í•„í„°ë§)
                is_json_tool_result = (
                    content.startswith('{"') or 
                    content.startswith("{'") or
                    ('"query"' in content and '"results"' in content) or
                    ('"url"' in content and '"title"' in content and '"content"' in content)
                )
                
                if not is_json_tool_result:
                    current_response += content
            else:
                # ëª¨ë“  ë‚´ìš© í‘œì‹œ
                current_response += content
            
            with placeholder.container():
                st.markdown(f"""
                <div class="streaming-message">
                    <div style="font-weight: bold; margin-bottom: 0.5rem; color: #1f77b4;">
                        ğŸ¤– AI ì‘ë‹µ
                    </div>
                    <div style="background: #f8f9fa; padding: 1rem; border-radius: 0.5rem; border-left: 4px solid #1f77b4; white-space: pre-wrap; line-height: 1.6;">
                        {current_response}
                    </div>
                </div>
                """, unsafe_allow_html=True)
        
        return current_response
    
    return current_response


def process_custom_mode(data, placeholder, current_response):
    """CUSTOM ëª¨ë“œ - ì»¤ìŠ¤í…€ ë°ì´í„° ì²˜ë¦¬"""
    if data:
        with placeholder.container():
            st.markdown(f"""
            <div class="streaming-message">
                <div style="font-weight: bold; margin-bottom: 0.5rem;">
                    ğŸ¯ CUSTOM ëª¨ë“œ: ì»¤ìŠ¤í…€ ë°ì´í„°
                </div>
                <div style="background: #e8f4fd; padding: 0.5rem; border-radius: 0.25rem; border-left: 4px solid #2196f3;">
                    <pre>{str(data)}</pre>
                </div>
            </div>
            """, unsafe_allow_html=True)
    
    return current_response


def display_error_info(data, placeholder):
    """ì˜¤ë¥˜ ì •ë³´ í‘œì‹œ"""
    with placeholder.container():
        st.error(f"ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {data}")


def detect_tool_usage(data, placeholder):
    """ë„êµ¬ ì‚¬ìš© ê°ì§€ (ëª¨ë“  ëª¨ë“œ ê³µí†µ)"""
    # messages ëª¨ë“œê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ë„êµ¬ ì‚¬ìš© í‘œì‹œ
    settings = st.session_state.get("stream_settings", {})
    stream_mode = settings.get("mode", "messages")
    
    if stream_mode == "messages":
        return  # messages ëª¨ë“œì—ì„œëŠ” ë³„ë„ ì²˜ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ìŠ¤í‚µ
    
    if isinstance(data, dict) and "messages" in data:
        messages = data["messages"] if isinstance(data["messages"], list) else [data["messages"]]
        
        for msg in messages:
            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                st.session_state.conversation_stats["tool_usage_count"] += 1
                
                with placeholder.container():
                    st.markdown("""
                    <div class="tool-usage">
                        ğŸ” Tavily ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤...
                    </div>
                    """, unsafe_allow_html=True)
                break


def display_metadata_info(step_data, metadata_placeholder):
    """ë©”íƒ€ë°ì´í„° ì •ë³´ í‘œì‹œ"""
    if not step_data:
        return
    
    latest_step = step_data[-1]
    
    with metadata_placeholder.container():
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ë‹¨ê³„", latest_step.get("step_number", 0))
        
        with col2:
            elapsed = latest_step.get("elapsed_time", 0)
            st.metric("ê²½ê³¼ ì‹œê°„", f"{elapsed:.2f}ì´ˆ")
        
        with col3:
            data_size = latest_step.get("data_size", 0)
            st.metric("ë°ì´í„° í¬ê¸°", f"{data_size:,} ë¬¸ì")
        
        with col4:
            mode = latest_step.get("stream_mode", "unknown")
            st.metric("ëª¨ë“œ", mode.upper())
        
        # ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© ì°¨íŠ¸
        if len(step_data) > 1:
            
            df = pd.DataFrame([
                {
                    "ë‹¨ê³„": step["step_number"],
                    "ë°ì´í„° í¬ê¸°": step["data_size"],
                    "ê²½ê³¼ ì‹œê°„": step["elapsed_time"]
                }
                for step in step_data
            ])
            
            st.line_chart(df.set_index("ë‹¨ê³„"))


def process_streaming_query(user_input: str):
    """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì¿¼ë¦¬ ì²˜ë¦¬"""
    start_time = time.time()
    first_token_time = None  # ì²« í† í° ì‹œê°„ ì¶”ì 
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({
        "role": "user",
        "content": user_input,
        "timestamp": time.strftime("%H:%M:%S")
    })
    
    # í†µê³„ ì—…ë°ì´íŠ¸
    st.session_state.conversation_stats["total_queries"] += 1
    
    # ì±„íŒ… í™”ë©´ì—ì„œ ì§ì ‘ ìŠ¤íŠ¸ë¦¬ë°í•˜ë¯€ë¡œ ë³„ë„ ì»¨í…Œì´ë„ˆ ë¶ˆí•„ìš”
    
    try:
        # ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        stream_settings = st.session_state.get("stream_settings", {})
        stream_mode = stream_settings.get("mode", "messages")
        show_metadata = stream_settings.get("show_metadata", False)
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
        if show_metadata:
            response_generator = st.session_state.agent.stream_response_with_metadata(
                user_input,
                thread_id=st.session_state.thread_id,
                stream_mode=stream_mode
            )
        else:
            response_generator = st.session_state.agent.stream_response(
                user_input,
                thread_id=st.session_state.thread_id,
                stream_mode=stream_mode
            )
        
        # ì²« í† í° ì‹œê°„ ì½œë°± í•¨ìˆ˜
        def record_first_token():
            nonlocal first_token_time
            if first_token_time is None:
                first_token_time = time.time() - start_time
        
        # ì±„íŒ… í™”ë©´ì—ì„œ ì§ì ‘ ìŠ¤íŠ¸ë¦¬ë°
        final_response = process_chat_streaming(
            response_generator,
            first_token_callback=record_first_token
        )
        
        # ì‘ë‹µ ì²˜ë¦¬ëŠ” process_chat_streamingì—ì„œ ì™„ë£Œë¨
        # ë³„ë„ì˜ ë©”ì‹œì§€ ì¶”ê°€ ë¶ˆí•„ìš”
        
        # ì„±ê³µ í†µê³„ ì—…ë°ì´íŠ¸
        st.session_state.conversation_stats["successful_responses"] += 1
        
        # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        response_time = time.time() - start_time
        current_avg = st.session_state.conversation_stats["avg_response_time"]
        total_queries = st.session_state.conversation_stats["total_queries"]
        
        # í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
        new_avg = ((current_avg * (total_queries - 1)) + response_time) / total_queries
        st.session_state.conversation_stats["avg_response_time"] = new_avg
        
        # í‰ê·  ì²« í† í° ì‹œê°„ ì—…ë°ì´íŠ¸
        if first_token_time is not None:
            current_first_token_avg = st.session_state.conversation_stats["avg_first_token_time"]
            new_first_token_avg = ((current_first_token_avg * (total_queries - 1)) + first_token_time) / total_queries
            st.session_state.conversation_stats["avg_first_token_time"] = new_first_token_avg
        
        # ì±„íŒ… í™”ë©´ì—ì„œ ì§ì ‘ ì²˜ë¦¬ë˜ë¯€ë¡œ ë³„ë„ ì •ë¦¬ ë¶ˆí•„ìš”
            
    except Exception as e:
        error_msg = f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        
        st.session_state.messages.append({
            "role": "error",
            "content": error_msg,
            "timestamp": time.strftime("%H:%M:%S")
        })


def process_chat_streaming(response_generator, first_token_callback=None):
    """ì±„íŒ… í™”ë©´ì—ì„œ ì§ì ‘ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬"""
    # ìŠ¤íŠ¸ë¦¬ë°ìš© ì»¨í…Œì´ë„ˆ ìƒì„±
    streaming_container = st.empty()
    
    full_response = ""
    first_token_recorded = False
    
    try:
        # ì´ˆê¸° ë©”ì‹œì§€ í‘œì‹œ
        with streaming_container.container():
            st.chat_message("assistant").write("ğŸ¤– ì‘ë‹µ ìƒì„± ì¤‘...")
        
        for step in response_generator:
            if isinstance(step, tuple) and len(step) == 2:
                message_chunk, metadata = step
                
                # í† í° ë‚´ìš© ì¶”ì¶œ
                if hasattr(message_chunk, 'content') and message_chunk.content:
                    content = message_chunk.content
                    
                    # ê¹”ë”í•œ ëª¨ë“œ: JSON í˜•íƒœì˜ ë„êµ¬ ê²°ê³¼ í•„í„°ë§
                    if not (content.startswith('{"') and '"results"' in content):
                        # ì²« í† í° ì‹œê°„ ê¸°ë¡
                        if not first_token_recorded and content.strip() and first_token_callback:
                            first_token_callback()
                            first_token_recorded = True
                        
                        full_response += content
                        
                        # ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ ì—…ë°ì´íŠ¸
                        with streaming_container.container():
                            st.chat_message("assistant").write(f"**[{time.strftime('%H:%M:%S')}]** {full_response} âš¡")
                
                # ë„êµ¬ ì‚¬ìš© ê°ì§€ ë° ì¹´ìš´íŠ¸
                if hasattr(message_chunk, 'tool_calls') and message_chunk.tool_calls:
                    if "counted_tool_calls" not in st.session_state:
                        st.session_state.counted_tool_calls = set()
                    
                    tool_call_id = f"{getattr(message_chunk, 'id', 'unknown')}_{message_chunk.tool_calls[0].get('name', 'unknown')}"
                    
                    if tool_call_id not in st.session_state.counted_tool_calls:
                        st.session_state.conversation_stats["tool_usage_count"] += 1
                        st.session_state.counted_tool_calls.add(tool_call_id)
        
        # ìµœì¢… ì‘ë‹µ ì •ë¦¬
        final_response = full_response.strip() if full_response.strip() else "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ìµœì¢… ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì €ì¥
        st.session_state.messages.append({
            "role": "assistant",
            "content": final_response,
            "timestamp": time.strftime("%H:%M:%S")
        })
        
        # ìµœì¢… ë©”ì‹œì§€ í‘œì‹œ (ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ)
        with streaming_container.container():
            st.chat_message("assistant").write(f"**[{time.strftime('%H:%M:%S')}]** {final_response}")
        
        return final_response
        
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ì²˜ë¦¬
        error_msg = f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        
        st.session_state.messages.append({
            "role": "error",
            "content": error_msg,
            "timestamp": time.strftime("%H:%M:%S")
        })
        
        with streaming_container.container():
            st.chat_message("assistant").error(f"**[{time.strftime('%H:%M:%S')}]** {error_msg}")
        
        return error_msg


def display_advanced_sidebar():
    """ì‚¬ì´ë“œë°” í‘œì‹œ"""
    with st.sidebar:
        st.markdown('<div class="main-header">ğŸ¤– PAI Web Agent</div>', unsafe_allow_html=True)
        
        # API í‚¤ ìƒíƒœ í‘œì‹œ
        st.subheader("ğŸ” API ìƒíƒœ")
        if check_api_keys():
            st.success("âœ… API í‚¤ ì„¤ì •ë¨")
        else:
            st.error("ğŸ”‘ API í‚¤ í•„ìš”")
            if st.button("ğŸ”‘ API í‚¤ ì„¤ì •í•˜ê¸°", use_container_width=True):
                st.session_state.show_api_setup = True
                st.rerun()
        
        # ì—ì´ì „íŠ¸ ì„¤ì •
        st.subheader("ğŸ”§ ì—ì´ì „íŠ¸ ì„¤ì •")
        
        # ëª¨ë¸ ì„ íƒ
        model_options = ["gpt-4.1-mini", "gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"]
        current_model = st.session_state.current_agent_settings["model"]
        current_index = model_options.index(current_model) if current_model in model_options else 0
        
        selected_model = st.selectbox(
            "ëª¨ë¸ ì„ íƒ",
            model_options,
            index=current_index,
            help="ì‚¬ìš©í•  OpenAI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”"
        )
        
        # ì˜¨ë„ ì„¤ì •
        temperature = st.slider(
            "ì°½ì˜ì„± ìˆ˜ì¤€ (Temperature)",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state.current_agent_settings["temperature"],
            step=0.1,
            help="ë†’ì„ìˆ˜ë¡ ë” ì°½ì˜ì ì¸ ì‘ë‹µ"
        )
        
        # ê²€ìƒ‰ ì„¤ì •
        st.subheader("ğŸ” ê²€ìƒ‰ ì„¤ì •")
        
        search_depth_options = ["basic", "advanced"]
        current_depth = st.session_state.current_agent_settings["search_depth"]
        depth_index = search_depth_options.index(current_depth) if current_depth in search_depth_options else 0
        
        search_depth = st.selectbox(
            "ê²€ìƒ‰ ê¹Šì´",
            search_depth_options,
            index=depth_index,
            help="advancedëŠ” ë” ì •í™•í•˜ì§€ë§Œ ë¹„ìš©ì´ 2ë°°"
        )
        
        max_results = st.slider(
            "ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜",
            min_value=1,
            max_value=10,
            value=st.session_state.current_agent_settings["max_results"],
            help="ë” ë§ì€ ê²°ê³¼ëŠ” ë” ì •í™•í•˜ì§€ë§Œ ëŠë¦¼"
        )
        
        # ë„ë©”ì¸ í•„í„°ë§ ì„¤ì •
        st.subheader("ğŸŒ ë„ë©”ì¸ í•„í„°ë§")
        
        # í¬í•¨ ë„ë©”ì¸
        include_domains_text = st.text_area(
            "í¬í•¨í•  ë„ë©”ì¸ (í•œ ì¤„ì— í•˜ë‚˜ì”©)",
            value="\n".join(st.session_state.current_agent_settings["include_domains"]),
            help="ê²€ìƒ‰ ê²°ê³¼ì— í¬í•¨í•  ë„ë©”ì¸ì„ ì…ë ¥í•˜ì„¸ìš”. ì˜ˆ: *.go.kr, *.or.kr"
        )
        include_domains = [d.strip() for d in include_domains_text.split("\n") if d.strip()]
        
        # ì œì™¸ ë„ë©”ì¸
        exclude_domains_text = st.text_area(
            "ì œì™¸í•  ë„ë©”ì¸ (í•œ ì¤„ì— í•˜ë‚˜ì”©)",
            value="\n".join(st.session_state.current_agent_settings["exclude_domains"]),
            help="ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì œì™¸í•  ë„ë©”ì¸ì„ ì…ë ¥í•˜ì„¸ìš”. ì˜ˆ: *.blog.*, *tistory.com"
        )
        exclude_domains = [d.strip() for d in exclude_domains_text.split("\n") if d.strip()]
        
        # ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • (messages ëª¨ë“œ ê³ ì •)
        st.subheader("ğŸ”„ ìŠ¤íŠ¸ë¦¬ë° ì„¤ì •")
        st.info("ğŸ’¬ **Messages ëª¨ë“œ**: ì‹¤ì‹œê°„ í† í° ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë¹ ë¥¸ ì‘ë‹µ ì œê³µ")
        stream_mode = "messages"
        
        show_metadata = st.checkbox(
            "ë©”íƒ€ë°ì´í„° í‘œì‹œ",
            value=False,
            help="ë‹¨ê³„ë³„ ì‹¤í–‰ ì‹œê°„, ë°ì´í„° í¬ê¸° ë“± ìƒì„¸ ì •ë³´ í‘œì‹œ"
        )
        
        clean_mode = st.checkbox(
            "ê¹”ë”í•œ ëª¨ë“œ",
            value=True,
            help="ë„êµ¬ ê²°ê³¼ë‚˜ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ìˆ¨ê¸°ê³  AI ì‘ë‹µë§Œ í‘œì‹œ"
        )
        
        # ì„¤ì • ë³€ê²½ ê°ì§€
        new_settings = {
            "model": selected_model,
            "temperature": temperature,
            "search_depth": search_depth,
            "max_results": max_results,
            "include_domains": include_domains,
            "exclude_domains": exclude_domains
        }
        
        # ì„¤ì •ì´ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if new_settings != st.session_state.current_agent_settings:
            st.session_state.settings_changed = True
        
        # ì„¸ì…˜ ìƒíƒœì— ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • ì €ì¥
        if "stream_settings" not in st.session_state:
            st.session_state.stream_settings = {}
        
        st.session_state.stream_settings.update({
            "mode": stream_mode,
            "show_metadata": show_metadata,
            "clean_mode": clean_mode,
            "search_depth": search_depth,
            "max_results": max_results,
            "include_domains": include_domains,
            "exclude_domains": exclude_domains
        })
        
        # ì—ì´ì „íŠ¸ ì¬ì´ˆê¸°í™”
        st.markdown("---")
        if st.button("ğŸ”„ ì„¤ì • ì ìš©", use_container_width=True, type="primary"):
            try:
                with st.spinner("âš™ï¸ ìƒˆë¡œìš´ ì„¤ì •ì„ ì ìš©í•˜ëŠ” ì¤‘..."):
                    # ê²€ìƒ‰ ì„¤ì • êµ¬ì„±
                    search_settings = {
                        "max_results": max_results,
                        "search_depth": search_depth,
                        "include_domains": include_domains if include_domains else None,
                        "exclude_domains": exclude_domains if exclude_domains else None,
                    }
                    
                    # ì—ì´ì „íŠ¸ ì¬ìƒì„± (ìƒˆ ì„¤ì • í¬í•¨)
                    st.session_state.agent = SupervisedAgent(
                        model_name=selected_model,
                        temperature=temperature,
                        search_settings=search_settings,
                    )
                    
                    # í˜„ì¬ ì„¤ì • ì—…ë°ì´íŠ¸
                    st.session_state.current_agent_settings = new_settings.copy()
                    st.session_state.settings_changed = False
                    
                st.success("âœ… ì„¤ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")
                time.sleep(1)
                st.rerun()
            except Exception as e:
                st.error(f"âŒ ì„¤ì • ì ìš© ì‹¤íŒ¨: {str(e)}")
        
        # í˜„ì¬ ì ìš©ëœ ì„¤ì • ë¯¸ë¦¬ë³´ê¸°
        if st.session_state.settings_changed:
            st.warning("âš ï¸ ë³€ê²½ì‚¬í•­ì´ ì•„ì§ ì ìš©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:
            st.success("âœ… ìµœì‹  ì„¤ì •ì´ ì ìš©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        
        st.markdown("---")
        
        # ëŒ€í™” ê´€ë¦¬
        st.subheader("ğŸ’¬ ëŒ€í™” ê´€ë¦¬")
        
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì‚­ì œ", use_container_width=True):
            # ìƒˆë¡œìš´ thread_id ìƒì„±ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
            st.session_state.thread_id = f"streamlit_session_{uuid.uuid4().hex[:8]}"
            st.session_state.messages = []
            st.session_state.conversation_stats = {
                "total_queries": 0,
                "successful_responses": 0,
                "tool_usage_count": 0,
                "avg_response_time": 0.0,
                "avg_first_token_time": 0.0
            }
            # ì¹´ìš´íŠ¸ëœ ë„êµ¬ í˜¸ì¶œ ê¸°ë¡ë„ ì´ˆê¸°í™”
            if "counted_tool_calls" in st.session_state:
                st.session_state.counted_tool_calls = set()
            st.success("âœ… ëŒ€í™” ê¸°ë¡ì´ ì™„ì „íˆ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
        
        # ëŒ€í™” ë‚´ë³´ë‚´ê¸°
        if st.session_state.messages:
            export_format = st.selectbox("ë‚´ë³´ë‚´ê¸° í˜•ì‹", ["TXT", "JSON", "CSV"])
            
            if export_format == "TXT":
                export_data = "\n".join([
                    f"[{msg.get('timestamp', 'N/A')}] {msg['role'].upper()}: {msg['content']}"
                    for msg in st.session_state.messages
                ])
                file_ext = "txt"
                mime_type = "text/plain"
            
            elif export_format == "JSON":
                export_data = json.dumps(st.session_state.messages, ensure_ascii=False, indent=2)
                file_ext = "json"
                mime_type = "application/json"
            
            else:  # CSV
                output = io.StringIO()
                writer = csv.writer(output)
                writer.writerow(["timestamp", "role", "content"])
                for msg in st.session_state.messages:
                    writer.writerow([msg.get('timestamp', 'N/A'), msg['role'], msg['content']])
                export_data = output.getvalue()
                file_ext = "csv"
                mime_type = "text/csv"
            
            st.download_button(
                label=f"ğŸ’¾ {export_format} ë‹¤ìš´ë¡œë“œ",
                data=export_data,
                file_name=f"chat_history_{st.session_state.thread_id}.{file_ext}",
                mime=mime_type,
                use_container_width=True
            )


def display_advanced_chat():
    """ê³ ê¸‰ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤"""
    # í˜„ì¬ ì ìš©ëœ ì„¤ì • ì‹¤ì‹œê°„ í‘œì‹œ
    display_current_settings()
    
    st.markdown("---")
    
    # ëŒ€í™” í†µê³„ í‘œì‹œ
    st.subheader("ğŸ“Š ëŒ€í™” í†µê³„")
    display_conversation_stats()
    
    st.markdown("---")
    
    # ì±„íŒ… ê¸°ë¡
    st.subheader("ğŸ’¬ ëŒ€í™” ê¸°ë¡")
    
    # ì±„íŒ… ì»¨í…Œì´ë„ˆ
    chat_container = st.container()
    
    with chat_container:
        if not st.session_state.messages:
            st.info("ğŸ‘‹ ì•ˆë…•í•˜ì„¸ìš”! ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        for message in st.session_state.messages:
            role = message["role"]
            content = message["content"]
            timestamp = message.get("timestamp", "")
            is_streaming = message.get("streaming", False)
            
            if role == "user":
                st.chat_message("user").write(f"**[{timestamp}]** {content}")
            elif role == "assistant":
                if is_streaming:
                    # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì¸ ë©”ì‹œì§€ëŠ” ì‹¤ì‹œê°„ í‘œì‹œ
                    st.chat_message("assistant").write(f"**[{timestamp}]** {content} âš¡")
                else:
                    # ì™„ë£Œëœ ë©”ì‹œì§€ëŠ” ì¼ë°˜ í‘œì‹œ
                    st.chat_message("assistant").write(f"**[{timestamp}]** {content}")
            else:  # error
                st.chat_message("assistant").error(f"**[{timestamp}]** {content}")
    
    # ì…ë ¥ ì˜ì—­
    st.markdown("---")
    
    # ë¹ ë¥¸ ì§ˆë¬¸ ë²„íŠ¼
    st.subheader("âš¡ ë¹ ë¥¸ ì§ˆë¬¸")
    
    col1, col2, col3 = st.columns(3)
    
    quick_questions = [
        "2025ë…„ ëŒ€í•œë¯¼êµ­ ì˜ˆì‚° ê·œëª¨ëŠ”?",
        "ìµœê·¼ í†µê³„ì²­ ë°œí‘œ ì£¼ìš” ì§€í‘œëŠ”?",
        "ì •ë¶€ ì •ì±… ìµœì‹  ë™í–¥ì€?",
        "ê³µê³µê¸°ê´€ ì±„ìš© ì •ë³´ëŠ”?",
        "ì§€ë°©ìì¹˜ë‹¨ì²´ ì¬ì • í˜„í™©ì€?",
        "êµ­ê°€í†µê³„í¬í„¸ ìµœì‹  ë°ì´í„°ëŠ”?"
    ]
    
    for i, question in enumerate(quick_questions):
        col = [col1, col2, col3][i % 3]
        with col:
            if st.button(question, key=f"quick_{i}", use_container_width=True):
                process_streaming_query(question)
                st.rerun()
    
    # ì‚¬ìš©ì ì…ë ¥
    st.subheader("âœï¸ ì§ˆë¬¸ ì…ë ¥")
    
    user_input = st.text_area(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
        placeholder="ì˜ˆ: ëŒ€êµ¬ê´‘ì—­ì‹œ 2025ë…„ ì¬ì • í˜„í™©ì€? ë˜ëŠ” í†µê³„ì²­ ìµœê·¼ ì¸êµ¬ í†µê³„ëŠ”?",
        height=100,
        key="user_input"
    )
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        if st.button("ğŸš€ ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡", use_container_width=True, type="primary"):
            if user_input.strip():
                process_streaming_query(user_input.strip())
                st.rerun()
            else:
                st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with col2:
        if st.button("ğŸ”„ ì…ë ¥ ì´ˆê¸°í™”", use_container_width=True):
            st.session_state.user_input = ""
            st.rerun()
    

def main():
    """ê³ ê¸‰ ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    initialize_session_state()
    
    # API í‚¤ ì„¤ì • ìƒíƒœ í™•ì¸
    if "show_api_setup" not in st.session_state:
        st.session_state.show_api_setup = False
    
    # API í‚¤ í™•ì¸
    if not check_api_keys() and not st.session_state.api_keys_set:
        if not st.session_state.show_api_setup:
            st.session_state.show_api_setup = True
        display_api_key_setup()
        return
    
    # ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
    if st.session_state.agent is None:
        try:
            with st.spinner("ğŸ¤– ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘..."):
                st.session_state.agent = create_agent()
            st.success("âœ… ì—ì´ì „íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
        except Exception as e:
            st.error(f"âŒ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            st.stop()
    
    # ì‚¬ì´ë“œë°” í‘œì‹œ
    display_advanced_sidebar()
    
    # ë©”ì¸ í—¤ë”
    st.markdown('<div class="main-header">ğŸ¤– PAI Web Agent</div>', unsafe_allow_html=True)
    
    st.markdown("""
    ### ğŸŒŸ ì£¼ìš” ê¸°ëŠ¥
    - **ğŸ›ï¸ ê³µê³µê¸°ê´€ ì •ë³´ íŠ¹í™”**: *.go.kr, *.or.kr ë„ë©”ì¸ ìš°ì„  ê²€ìƒ‰
    - **ğŸ” ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰**: Tavily APIë¡œ ìµœì‹  ì •ë¶€/ê³µê³µê¸°ê´€ ì •ë³´ ìˆ˜ì§‘
    - **ğŸ’¬ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ**: ì‘ë‹µ ìƒì„± ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸
    - **ğŸ“Š ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´**: ê³µì‹ ì‚¬ì´íŠ¸ ìš°ì„ , ê°œì¸ ë¸”ë¡œê·¸/SNS ì œì™¸
    - **ğŸŒ ë„ë©”ì¸ í•„í„°ë§**: ì •ë¶€ê¸°ê´€, ê³µê³µê¸°ê´€ ì‚¬ì´íŠ¸ë§Œ ê²€ìƒ‰ ê°€ëŠ¥
    - **ğŸ¯ ê³µê³µì •ë³´ ë¹ ë¥¸ ì§ˆë¬¸**: ì˜ˆì‚°, í†µê³„, ì •ì±… ë“± ë¯¸ë¦¬ ì¤€ë¹„ëœ ì§ˆë¬¸
    """)
    
    # ê³ ê¸‰ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    display_advanced_chat()


if __name__ == "__main__":
    main()