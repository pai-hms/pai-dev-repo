"""
SQL Agent ì„œë¹„ìŠ¤ - Supervisor íŒ¨í„´
"""
import asyncio
import logging
from typing import Dict, Any, Optional, AsyncGenerator
from datetime import datetime

from .graph import create_sql_agent_graph
from .nodes import create_initial_state

logger = logging.getLogger(__name__)


class SQLAgentService:
    """SQL Agent ì„œë¹„ìŠ¤ (Supervisor íŒ¨í„´)"""
    
    _instance: Optional['SQLAgentService'] = None
    _lock = asyncio.Lock()
    
    def __init__(self):
        self._agent_graph = None
        self._session_service = None
        self._initialized = False
    
    @classmethod
    async def get_instance(cls) -> 'SQLAgentService':
        """ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        if cls._instance is None:
            async with cls._lock:
                if cls._instance is None:
                    cls._instance = cls()
                    await cls._instance._initialize()
        return cls._instance
    
    async def _initialize(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        if self._initialized:
            return
            
        logger.info("SQL Agent ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹œì‘")
        
        try:
            # SQL Agent ê·¸ë˜í”„ ìƒì„±
            self._agent_graph = await create_sql_agent_graph()
            
            # âœ… PostgresSaver ì‚¬ìš©ìœ¼ë¡œ ë³„ë„ ì„¸ì…˜ ì„œë¹„ìŠ¤ ë¶ˆí•„ìš”
            # self._session_service = await get_session_service()   
            
            self._initialized = True
            logger.info("SQL Agent ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"SQL Agent ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._initialized = False
            raise
    
    async def process_query(
        self,
        question: str,
        thread_id: Optional[str] = None,
        session_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """ì§ˆë¬¸ ì²˜ë¦¬ (ë¹„ìŠ¤íŠ¸ë¦¬ë°)"""
        try:
            if not self._initialized:
                await self._initialize()
            
            # ì´ˆê¸° ìƒíƒœ ìƒì„±
            initial_state = await create_initial_state(question, thread_id or session_id or "default")
            
            # ê·¸ë˜í”„ ì‹¤í–‰
            config = {
                "configurable": {"thread_id": thread_id or session_id or "default"},
                "recursion_limit": 50
            }
            
            result = await self._agent_graph.ainvoke(initial_state, config=config)
            
            logger.info(f"ì¿¼ë¦¬ ì²˜ë¦¬ ì™„ë£Œ: {question[:50]}...")
            
            return {
                "success": True,
                "result": result.get("data", ""),
                "sql_query": result.get("sql_query", ""),
                "messages": result.get("messages", [])
            }
            
        except Exception as e:
            logger.error(f"ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "result": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }
    
    async def process_query_stream(
        self,
        question: str,
        thread_id: Optional[str] = None,
        session_id: Optional[str] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """ì§ˆë¬¸ ì²˜ë¦¬ (ê¸°ì¡´ ìŠ¤íŠ¸ë¦¬ë° + UI ì§„í–‰ìƒí™© ì¶”ê°€)"""
        try:
            if not self._initialized:
                await self._initialize()
        
            # âœ… ì„¸ì…˜ íˆìŠ¤í† ë¦¬ë¥¼ í¬í•¨í•œ ì´ˆê¸° ìƒíƒœ ìƒì„±
            initial_state = await create_initial_state(question, thread_id or session_id or "default")
        
            config = {
                "configurable": {"thread_id": thread_id or session_id or "default"},
                "recursion_limit": 50
            }
            
            # ìµœì¢… ì‘ë‹µ ì €ì¥ì„ ìœ„í•œ ë³€ìˆ˜
            final_response = None
        
            # ì‹œì‘ ì‹ í˜¸
            yield {
                "type": "start",
                "content": "SQL ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...",
                "timestamp": datetime.now().isoformat()
            }
            
            # ë””ë²„ê¹… ì¹´ìš´í„°
            chunk_count = 0
            token_count = 0
            
            
            # **ğŸ¯ ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ í†µí•© (ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€)**
            
            # **ë‹¨ìˆœí™”ëœ ìŠ¤íŠ¸ë¦¬ë° (ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€)**
            async def merge_streams():
                """ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ í† í° ë° ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§"""
                
                # âœ… í•˜ë‚˜ì˜ ìŠ¤íŠ¸ë¦¼ë§Œ ì‚¬ìš©
                token_stream = self._agent_graph.astream(
                    initial_state,
                    config=config,
                    stream_mode="messages"
                )
                
                try:
                    # ë©”ì¸ í† í° ìŠ¤íŠ¸ë¦¬ë°
                    async for chunk in token_stream:
                        nonlocal chunk_count, token_count
                        chunk_count += 1
                        
                        # ê¸°ì¡´ í† í° ìŠ¤íŠ¸ë¦¬ë° ë¡œì§ (ë³€ê²½ ì—†ìŒ)
                        if isinstance(chunk, tuple) and len(chunk) >= 1:
                            message = chunk[0] if len(chunk) > 0 else None
                            metadata = chunk[1] if len(chunk) > 1 else None
                            
                            if message and hasattr(message, 'content'):
                                logger.info(f"   Content: '{message.content[:50]}...'")
                            
                            # response ë…¸ë“œì—ì„œë§Œ í† í° ìŠ¤íŠ¸ë¦¬ë°
                            if (message and 
                                hasattr(message, 'content') and 
                                message.content and  
                                message.content.strip() and
                                metadata and
                                metadata.get('langgraph_node') == 'response'):
                                
                                token_count += 1
                                yield {
                                    "type": "token",
                                    "content": message.content,
                                    "timestamp": datetime.now().isoformat()
                                }
                            
                            # ë…¸ë“œ ì—…ë°ì´íŠ¸
                            elif metadata and metadata.get('langgraph_node'):
                                node_name = metadata.get('langgraph_node')
                                yield {
                                    "type": "node_update",
                                    "node": node_name,
                                    "content": f"ğŸ”„ {node_name} ì‹¤í–‰ ì¤‘...",
                                    "timestamp": datetime.now().isoformat()
                                }
                        
                        else:
                            logger.warning(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ chunk í˜•íƒœ: {type(chunk)}")
                    
                except Exception as stream_error:
                    logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì˜¤ë¥˜: {stream_error}")
                    yield {
                        "type": "error",
                        "content": f"ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {str(stream_error)}",
                        "timestamp": datetime.now().isoformat()
                    }
                
                logger.info(f"ğŸ“Š ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ - ì´ chunk: {chunk_count}, í† í°: {token_count}")
            
            # **âœ… ë‹¨ìˆœí™”ëœ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹**
            try:
                logger.info("ğŸ” ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ - stream_mode='messages'")
                
                async for result_chunk in merge_streams():
                    # âœ… ìµœì¢… ì‘ë‹µ ìºì‹œ
                    if result_chunk.get("type") == "token":
                        if final_response is None:
                            final_response = ""
                        final_response += result_chunk.get("content", "")
                    
                    yield result_chunk
                
                logger.info(f"ğŸ“ PostgresSaverë¥¼ í†µí•´ ëŒ€í™” ìƒíƒœ ìë™ ì €ì¥ë¨ (thread_id: {thread_id})")
            
            except Exception as stream_error:
                logger.error(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {stream_error}")
                
                # Fallback ì²˜ë¦¬...
                try:
                    result = await self._agent_graph.ainvoke(initial_state, config=config)
                    
                    if "messages" in result:
                        for message in reversed(result["messages"]):
                            if (hasattr(message, 'type') and 
                                message.type == "ai" and 
                                message.content):
                                
                                for char in message.content:
                                    yield {
                                        "type": "token",
                                        "content": char,
                                        "timestamp": datetime.now().isoformat()
                                    }
                                break
                        
                except Exception as fallback_error:
                    logger.error(f"âŒ Fallback ì˜¤ë¥˜: {fallback_error}")
                    yield {
                        "type": "error",
                        "content": "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                        "timestamp": datetime.now().isoformat()
                    }
            
            # ì™„ë£Œ ì‹ í˜¸
            yield {
                "type": "done",
                "content": "âœ… SQL ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ ì „ì²´ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            yield {
                "type": "error",
                "content": f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }

async def _monitor_events(self, initial_state, config):
    """ì´ë²¤íŠ¸ ëª¨ë‹ˆí„°ë§ (ë„êµ¬ ì‹¤í–‰, ë…¸ë“œ ìƒíƒœ)"""
    async for event in self._agent_graph.astream_events(
        initial_state, config=config, version="v1"
    ):
        event_type = event.get("event", "")
        event_name = event.get("name", "")
        
        if event_type == "on_tool_start":
            yield {
                "type": "tool_start",
                "tool": event.get("name", ""),
                "content": f"ğŸ”§ {event.get('name', '')} ì‹¤í–‰ ì¤‘...",
                "timestamp": datetime.now().isoformat()
            }
        
        elif event_type == "on_tool_end":
            yield {
                "type": "tool_end",
                "tool": event.get("name", ""),
                "content": f"âœ… {event.get('name', '')} ì™„ë£Œ",
                "timestamp": datetime.now().isoformat()
            }


# í¸ì˜ì„±ì„ ìœ„í•œ ì „ì—­ í•¨ìˆ˜ë“¤
async def get_sql_agent_service() -> SQLAgentService:
    """SQL Agent ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return await SQLAgentService.get_instance()


