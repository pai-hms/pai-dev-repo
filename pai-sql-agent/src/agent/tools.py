"""
Agent ë„êµ¬ ì •ì˜
SQL ì¿¼ë¦¬ ì‹¤í–‰ ë„êµ¬ì™€ ê´€ë ¨ ìœ í‹¸ë¦¬í‹°
"""
import re
import logging
from typing import List, Dict, Any, Tuple, Optional
from langchain_core.tools import tool
from sqlalchemy.exc import SQLAlchemyError

from src.database.connection import get_database_manager
from src.database.repository import DatabaseService


logger = logging.getLogger(__name__)


class SQLQueryValidator:
    """SQL ì¿¼ë¦¬ ê²€ì¦ê¸°"""
    
    # ìœ„í—˜í•œ í‚¤ì›Œë“œë“¤
    DANGEROUS_KEYWORDS = [
        'DROP', 'DELETE', 'UPDATE', 'INSERT', 'CREATE', 'ALTER', 
        'TRUNCATE', 'REPLACE', 'MERGE', 'CALL', 'EXEC', 'EXECUTE'
    ]
    
    # í—ˆìš©ëœ í…Œì´ë¸”ë“¤
    ALLOWED_TABLES = [
        'population_stats', 'population_search_stats', 'household_stats', 'house_stats', 
        'company_stats', 'farm_household_stats', 'forestry_household_stats', 
        'fishery_household_stats', 'household_member_stats', 'industry_code_stats'
    ]
    
    @classmethod
    def validate_query(cls, query: str) -> Tuple[bool, Optional[str]]:
        """ì¿¼ë¦¬ ê²€ì¦"""
        # ê¸°ë³¸ ê²€ì¦
        if not query or not query.strip():
            return False, "ë¹ˆ ì¿¼ë¦¬ì…ë‹ˆë‹¤"
        
        query_upper = query.upper()
        
        # ìœ„í—˜í•œ í‚¤ì›Œë“œ ê²€ì‚¬
        for keyword in cls.DANGEROUS_KEYWORDS:
            if keyword in query_upper:
                return False, f"í—ˆìš©ë˜ì§€ ì•Šì€ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {keyword}"
        
        # SELECT ë¬¸ì¸ì§€ í™•ì¸
        if not query_upper.strip().startswith('SELECT'):
            return False, "SELECT ë¬¸ë§Œ í—ˆìš©ë©ë‹ˆë‹¤"
        
        # ì„¸ë¯¸ì½œë¡  ê°œìˆ˜ í™•ì¸ (ë‹¤ì¤‘ ì¿¼ë¦¬ ë°©ì§€)
        if query.count(';') > 1:
            return False, "ë‹¤ì¤‘ ì¿¼ë¦¬ëŠ” í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤"
        
        # í…Œì´ë¸” ì´ë¦„ ê²€ì¦
        table_pattern = r'\bFROM\s+([a-zA-Z_][a-zA-Z0-9_]*)'
        tables = re.findall(table_pattern, query_upper)
        
        for table in tables:
            if table.lower() not in cls.ALLOWED_TABLES:
                return False, f"í—ˆìš©ë˜ì§€ ì•Šì€ í…Œì´ë¸”ì…ë‹ˆë‹¤: {table}"
        
        # JOINì— ì‚¬ìš©ëœ í…Œì´ë¸”ë„ ê²€ì¦
        join_pattern = r'\bJOIN\s+([a-zA-Z_][a-zA-Z0-9_]*)'
        join_tables = re.findall(join_pattern, query_upper)
        
        for table in join_tables:
            if table.lower() not in cls.ALLOWED_TABLES:
                return False, f"í—ˆìš©ë˜ì§€ ì•Šì€ í…Œì´ë¸”ì…ë‹ˆë‹¤: {table}"
        
        return True, None


@tool
async def execute_sql_query(query: str) -> str:
    """
    SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        query: ì‹¤í–‰í•  SQL ì¿¼ë¦¬ (SELECT ë¬¸ë§Œ í—ˆìš©)
    
    Returns:
        ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜
    """
    try:
        # ì¿¼ë¦¬ ê²€ì¦
        is_valid, error_msg = SQLQueryValidator.validate_query(query)
        if not is_valid:
            return f"ì¿¼ë¦¬ ê²€ì¦ ì‹¤íŒ¨: {error_msg}"
        
        # ì¿¼ë¦¬ ì‹¤í–‰
        db_manager = get_database_manager()
        
        async with db_manager.get_async_session() as session:
            db_service = DatabaseService(session)
            results = await db_service.execute_raw_query(query)
        
        # ê²°ê³¼ í¬ë§·íŒ…
        if not results:
            return "ì¿¼ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # ê²°ê³¼ë¥¼ í…Œì´ë¸” í˜•íƒœë¡œ í¬ë§·íŒ…
        if len(results) > 0:
            # ì»¬ëŸ¼ í—¤ë”
            headers = list(results[0].keys())
            
            # í…Œì´ë¸” ìƒì„±
            table_lines = []
            
            # í—¤ë” ë¼ì¸
            header_line = " | ".join(str(h) for h in headers)
            table_lines.append(header_line)
            table_lines.append("-" * len(header_line))
            
            # ë°ì´í„° ë¼ì¸ë“¤ (ìµœëŒ€ 50ê°œ í–‰ë§Œ í‘œì‹œ)
            max_rows = min(50, len(results))
            for i in range(max_rows):
                row = results[i]
                row_line = " | ".join(str(row.get(h, "")) for h in headers)
                table_lines.append(row_line)
            
            # ë” ë§ì€ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° ë©”ì‹œì§€ ì¶”ê°€
            if len(results) > max_rows:
                table_lines.append(f"... ({len(results) - max_rows}ê°œ í–‰ ë” ìˆìŒ)")
            
            result_text = "\n".join(table_lines)
            return f"ì¿¼ë¦¬ ì‹¤í–‰ ì™„ë£Œ ({len(results)}ê°œ í–‰):\n\n{result_text}"
        
        return "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
    except SQLAlchemyError as e:
        logger.error(f"SQL ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
        return f"SQL ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


@tool
async def get_table_info(table_name: str) -> str:
    """
    í…Œì´ë¸”ì˜ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    Args:
        table_name: ì¡°íšŒí•  í…Œì´ë¸” ì´ë¦„
    
    Returns:
        í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ë³´
    """
    try:
        if table_name not in SQLQueryValidator.ALLOWED_TABLES:
            return f"í—ˆìš©ë˜ì§€ ì•Šì€ í…Œì´ë¸”ì…ë‹ˆë‹¤: {table_name}"
        
        db_manager = get_database_manager()
        
        async with db_manager.get_async_session() as session:
            db_service = DatabaseService(session)
            schema_info = await db_service.get_table_schema(table_name)
        
        if not schema_info:
            return f"í…Œì´ë¸” '{table_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ìŠ¤í‚¤ë§ˆ ì •ë³´ í¬ë§·íŒ…
        lines = [f"í…Œì´ë¸”: {table_name}", ""]
        
        for column in schema_info:
            col_name = column['column_name']
            data_type = column['data_type']
            is_nullable = column['is_nullable']
            default_value = column['column_default']
            
            nullable_text = "NULL í—ˆìš©" if is_nullable == 'YES' else "NOT NULL"
            default_text = f", ê¸°ë³¸ê°’: {default_value}" if default_value else ""
            
            lines.append(f"- {col_name}: {data_type} ({nullable_text}{default_text})")
        
        return "\n".join(lines)
        
    except Exception as e:
        logger.error(f"í…Œì´ë¸” ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return f"í…Œì´ë¸” ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


@tool
async def get_available_tables() -> str:
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  í…Œì´ë¸” ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        í…Œì´ë¸” ëª©ë¡ê³¼ ê°„ë‹¨í•œ ì„¤ëª…
    """
    try:
        db_manager = get_database_manager()
        
        async with db_manager.get_async_session() as session:
            db_service = DatabaseService(session)
            tables = await db_service.get_all_tables()
        
        # í…Œì´ë¸” ì„¤ëª… ë§¤í•‘
        table_descriptions = {
            'population_stats': 'ì´ì¡°ì‚¬ ì£¼ìš”ì§€í‘œ (2015-2023)',
            'population_search_stats': 'ì¸êµ¬í†µê³„ ë°ì´í„°',
            'household_stats': 'ê°€êµ¬ í†µê³„ (2015-2023)',
            'house_stats': 'ì£¼íƒ í†µê³„ (2015-2023)',
            'company_stats': 'ì‚¬ì—…ì²´ í†µê³„ (2000-2023)',
            'farm_household_stats': 'ë†ê°€ í†µê³„ (ë†ë¦¼ì–´ì—…ì´ì¡°ì‚¬)',
            'forestry_household_stats': 'ì„ê°€ í†µê³„ (ë†ë¦¼ì–´ì—…ì´ì¡°ì‚¬)',
            'fishery_household_stats': 'ì–´ê°€ í†µê³„ (ë†ë¦¼ì–´ì—…ì´ì¡°ì‚¬)',
            'household_member_stats': 'ê°€êµ¬ì› í†µê³„ (ë†ë¦¼ì–´ì—…ì´ì¡°ì‚¬)',
            'industry_code_stats': 'ì‚°ì—…ë¶„ë¥˜ë³„ í†µê³„ ë°ì´í„°'
        }
        
        lines = ["ì‚¬ìš© ê°€ëŠ¥í•œ í…Œì´ë¸” ëª©ë¡:", ""]
        
        for table in sorted(tables):
            description = table_descriptions.get(table, "ì„¤ëª… ì—†ìŒ")
            lines.append(f"- {table}: {description}")
        
        return "\n".join(lines)
        
    except Exception as e:
        logger.error(f"í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return f"í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


@tool
async def search_administrative_area(search_term: str) -> str:
    """
    í–‰ì •êµ¬ì—­ëª…ìœ¼ë¡œ ê²€ìƒ‰í•˜ì—¬ í–‰ì •êµ¬ì—­ì½”ë“œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    
    Args:
        search_term: ê²€ìƒ‰í•  í–‰ì •êµ¬ì—­ëª… (ì˜ˆ: "í¬í•­", "ì„œìš¸", "ê°•ë‚¨êµ¬")
    
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ (í–‰ì •êµ¬ì—­ì½”ë“œì™€ ì´ë¦„)
    """
    try:
        # ìµœì‹  ì—°ë„ ë°ì´í„°ì—ì„œ ê²€ìƒ‰
        query = """
        SELECT DISTINCT adm_cd, adm_nm 
        FROM population_stats 
        WHERE year = 2023 
        AND adm_nm ILIKE %s
        ORDER BY LENGTH(adm_cd), adm_cd
        LIMIT 20
        """
        
        db_manager = get_database_manager()
        
        async with db_manager.get_async_session() as session:
            db_service = DatabaseService(session)
            results = await db_service.execute_raw_query(
                query.replace('%s', f"'%{search_term}%'")
            )
        
        if not results:
            return f"'{search_term}'ì™€ ì¼ì¹˜í•˜ëŠ” í–‰ì •êµ¬ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        lines = [f"'{search_term}' ê²€ìƒ‰ ê²°ê³¼:", ""]
        
        for result in results:
            adm_cd = result['adm_cd']
            adm_nm = result['adm_nm']
            
            # í–‰ì •êµ¬ì—­ ë ˆë²¨ íŒë‹¨
            if len(adm_cd) == 2:
                level = "ì‹œë„"
            elif len(adm_cd) == 5:
                level = "ì‹œêµ°êµ¬"
            elif len(adm_cd) == 8:
                level = "ìë©´ë™"
            else:
                level = "ê¸°íƒ€"
            
            lines.append(f"- {adm_cd}: {adm_nm} ({level})")
        
        return "\n".join(lines)
        
    except Exception as e:
        logger.error(f"í–‰ì •êµ¬ì—­ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return f"í–‰ì •êµ¬ì—­ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


@tool
async def semantic_search(query: str, limit: int = 5) -> str:
    """
    ì˜ë¯¸ ê²€ìƒ‰ì„ í†µí•´ ê´€ë ¨ í†µê³„ ë°ì´í„°ë‚˜ ë¬¸ì„œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰í•  ì§ˆë¬¸ì´ë‚˜ í‚¤ì›Œë“œ
        limit: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜ (ê¸°ë³¸ê°’: 5)
    
    Returns:
        ìœ ì‚¬í•œ ë¬¸ì„œë“¤ê³¼ ê´€ë ¨ ì •ë³´
    """
    try:
        from langchain_openai import OpenAIEmbeddings
        from src.config.settings import get_settings
        
        settings = get_settings()
        
        # OpenAI ì„ë² ë”© ìƒì„±
        embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            openai_api_key=settings.openai_api_key
        )
        
        # ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        query_vector = await embeddings.aembed_query(query)
        
        # pgvectorë¥¼ ì‚¬ìš©í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰
        search_query = """
        SELECT 
            content,
            source_table,
            source_id,
            meta_data,
            1 - (embedding <=> %s::vector) as similarity
        FROM document_embeddings
        WHERE embedding IS NOT NULL
        ORDER BY embedding <=> %s::vector
        LIMIT %s
        """
        
        db_manager = get_database_manager()
        async with db_manager.get_async_session() as session:
            db_service = DatabaseService(session)
            
            # ë²¡í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            vector_str = f"[{','.join(map(str, query_vector))}]"
            
            results = await db_service.execute_raw_query(
                search_query.replace('%s', '$1').replace('%s', '$2').replace('%s', '$3'),
                (vector_str, vector_str, limit)
            )
        
        if not results:
            return f"'{query}'ì™€ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € create_embeddings_for_stats ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ë°ì´í„°ë¥¼ ì„ë² ë”©í•˜ì„¸ìš”."
        
        lines = [f"ğŸ” '{query}' ì˜ë¯¸ ê²€ìƒ‰ ê²°ê³¼:", ""]
        
        for i, result in enumerate(results, 1):
            similarity = f"{result['similarity']:.3f}"
            content_preview = result['content'][:100] + "..." if len(result['content']) > 100 else result['content']
            
            lines.append(f"{i}. ìœ ì‚¬ë„: {similarity}")
            lines.append(f"   ë‚´ìš©: {content_preview}")
            lines.append(f"   ì¶œì²˜: {result['source_table']} (ID: {result['source_id']})")
            
            # ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ í‘œì‹œ
            if result.get('meta_data'):
                meta_data = result['meta_data']
                if isinstance(meta_data, dict) and meta_data:
                    meta_info = []
                    for key, value in meta_data.items():
                        if value is not None:
                            meta_info.append(f"{key}: {value}")
                    if meta_info:
                        lines.append(f"   ì„¸ë¶€ì •ë³´: {', '.join(meta_info[:3])}")  # ìµœëŒ€ 3ê°œë§Œ
            
            lines.append("")
        
        return "\n".join(lines)
        
    except Exception as e:
        logger.error(f"ì˜ë¯¸ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return f"ì˜ë¯¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


@tool
async def create_embeddings_for_stats(year: int = 2023) -> str:
    """
    í†µê³„ ë°ì´í„°ì˜ ì„¤ëª…ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        year: ì„ë² ë”©ì„ ìƒì„±í•  ì—°ë„ (ê¸°ë³¸ê°’: 2023)
    
    Returns:
        ì„ë² ë”© ìƒì„± ê²°ê³¼
    """
    try:
        from langchain_openai import OpenAIEmbeddings
        from src.config.settings import get_settings
        
        settings = get_settings()
        
        # OpenAI ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            openai_api_key=settings.openai_api_key
        )
        
        # í†µê³„ ë°ì´í„° ìš”ì•½ ì •ë³´ ì¡°íšŒ
        summary_query = """
        SELECT 
            CONCAT('stats_', adm_cd, '_', year) as record_id,
            adm_cd,
            adm_nm,
            year,
            tot_ppltn,
            avg_age,
            ppltn_dnsty,
            male_ppltn,
            female_ppltn,
            CONCAT(
                adm_nm, ' ', year, 'ë…„ í†µê³„: ',
                'ì´ì¸êµ¬ ', COALESCE(tot_ppltn::text, 'ì •ë³´ì—†ìŒ'), 'ëª…, ',
                'í‰ê· ì—°ë ¹ ', COALESCE(avg_age::text, 'ì •ë³´ì—†ìŒ'), 'ì„¸, ',
                'ì¸êµ¬ë°€ë„ ', COALESCE(ppltn_dnsty::text, 'ì •ë³´ì—†ìŒ'), 'ëª…/ã¢, ',
                'ë‚¨ì„± ', COALESCE(male_ppltn::text, 'ì •ë³´ì—†ìŒ'), 'ëª…, ',
                'ì—¬ì„± ', COALESCE(female_ppltn::text, 'ì •ë³´ì—†ìŒ'), 'ëª…'
            ) as description
        FROM population_stats 
        WHERE year = %s
        AND tot_ppltn IS NOT NULL
        ORDER BY adm_cd
        """
        
        db_manager = get_database_manager()
        async with db_manager.get_async_session() as session:
            db_service = DatabaseService(session)
            stats = await db_service.execute_raw_query(summary_query, (year,))
        
        if not stats:
            return f"{year}ë…„ í†µê³„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        embedded_count = 0
        error_count = 0
        
        # ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„± (ì†ë„ í–¥ìƒ)
        descriptions = [stat['description'] for stat in stats]
        
        try:
            # ì„ë² ë”© ë°°ì¹˜ ìƒì„±
            embedding_vectors = await embeddings.aembed_documents(descriptions)
            
            # ê° í†µê³„ ë°ì´í„°ì— ëŒ€í•´ ì„ë² ë”© ì €ì¥
            for stat, embedding_vector in zip(stats, embedding_vectors):
                try:
                    # ë©”íƒ€ë°ì´í„° êµ¬ì„±
                    metadata = {
                        'year': stat['year'],
                        'total_population': stat['tot_ppltn'],
                        'avg_age': stat['avg_age'],
                        'population_density': stat['ppltn_dnsty'],
                        'male_population': stat['male_ppltn'],
                        'female_population': stat['female_ppltn']
                    }
                    
                    # ë²¡í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                    vector_str = f"[{','.join(map(str, embedding_vector))}]"
                    
                    # DBì— ì €ì¥ (UPSERT)
                    upsert_query = """
                    INSERT INTO document_embeddings (content, source_table, source_id, meta_data, embedding)
                    VALUES (%s, 'population_stats', %s, %s, %s::vector)
                    ON CONFLICT (source_table, source_id) 
                    DO UPDATE SET 
                        content = EXCLUDED.content,
                        meta_data = EXCLUDED.meta_data,
                        embedding = EXCLUDED.embedding,
                        updated_at = CURRENT_TIMESTAMP
                    """
                    
                    await db_service.execute_raw_query(
                        upsert_query,
                        (
                            stat['description'],
                            stat['record_id'],
                            metadata,
                            vector_str
                        )
                    )
                    embedded_count += 1
                    
                except Exception as e:
                    logger.error(f"ê°œë³„ ì„ë² ë”© ì €ì¥ ì˜¤ë¥˜ (ID: {stat['record_id']}): {e}")
                    error_count += 1
                    continue
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
            return f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        
        result_msg = f"âœ… {year}ë…„ í†µê³„ ë°ì´í„° {embedded_count}ê°œì˜ ì„ë² ë”©ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤."
        if error_count > 0:
            result_msg += f"\nâš ï¸  {error_count}ê°œ ë ˆì½”ë“œì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        
        return result_msg
        
    except Exception as e:
        logger.error(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


@tool
async def get_embedding_stats() -> str:
    """
    í˜„ì¬ ì €ì¥ëœ ì„ë² ë”© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    Returns:
        ì„ë² ë”© ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©
    """
    try:
        stats_query = """
        SELECT 
            source_table,
            COUNT(*) as total_count,
            COUNT(embedding) as embedded_count,
            MIN(created_at) as oldest_created,
            MAX(updated_at) as latest_updated
        FROM document_embeddings
        GROUP BY source_table
        ORDER BY total_count DESC
        """
        
        db_manager = get_database_manager()
        async with db_manager.get_async_session() as session:
            db_service = DatabaseService(session)
            results = await db_service.execute_raw_query(stats_query)
        
        if not results:
            return "ì €ì¥ëœ ì„ë² ë”© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        lines = ["ğŸ“Š ì„ë² ë”© ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©:", ""]
        
        total_records = 0
        total_embedded = 0
        
        for result in results:
            source = result['source_table']
            total = result['total_count']
            embedded = result['embedded_count']
            oldest = result['oldest_created']
            latest = result['latest_updated']
            
            total_records += total
            total_embedded += embedded
            
            completion_rate = (embedded / total * 100) if total > 0 else 0
            
            lines.append(f"ğŸ—‚ï¸  {source}:")
            lines.append(f"   - ì´ ë ˆì½”ë“œ: {total:,}ê°œ")
            lines.append(f"   - ì„ë² ë”© ì™„ë£Œ: {embedded:,}ê°œ ({completion_rate:.1f}%)")
            lines.append(f"   - ìƒì„±ì¼: {oldest.strftime('%Y-%m-%d') if oldest else 'N/A'}")
            lines.append(f"   - ìµœì¢… ì—…ë°ì´íŠ¸: {latest.strftime('%Y-%m-%d %H:%M') if latest else 'N/A'}")
            lines.append("")
        
        # ì „ì²´ ìš”ì•½
        overall_completion = (total_embedded / total_records * 100) if total_records > 0 else 0
        lines.append("ğŸ“ˆ ì „ì²´ ìš”ì•½:")
        lines.append(f"   - ì´ ë ˆì½”ë“œ: {total_records:,}ê°œ")
        lines.append(f"   - ì„ë² ë”© ì™„ë£Œ: {total_embedded:,}ê°œ ({overall_completion:.1f}%)")
        
        return "\n".join(lines)
        
    except Exception as e:
        logger.error(f"ì„ë² ë”© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return f"ì„ë² ë”© í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


# ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤
AVAILABLE_TOOLS = [
    execute_sql_query,
    get_table_info,
    get_available_tables,
    search_administrative_area,
    semantic_search,
    create_embeddings_for_stats,
    get_embedding_stats,
]